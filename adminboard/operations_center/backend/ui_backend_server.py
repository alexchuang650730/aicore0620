# -*- coding: utf-8 -*-
"""
é‹ç‡Ÿä¸­å¿ƒæ•´åˆå¾Œç«¯APIæœå‹™
Operations Center Integrated Backend API Service
æ•´åˆç³»çµ±ç›£æ§å’Œå·¥ä½œæµç®¡ç†åŠŸèƒ½çš„çµ±ä¸€å¾Œå°æœå‹™
"""

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import os
import json
import time
import logging
import psutil
import sqlite3
from datetime import datetime, timedelta
import requests
import threading
from typing import Dict, List, Any
import asyncio

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# é…ç½®
DATABASE_FILE = 'operations_center.db'
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'txt', 'pdf', 'doc', 'docx', 'xls', 'xlsx', 'html', 'htm', 'md', 'csv', 'json', 'yaml', 'yml', 'log'}
MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB

# å‘Šè­¦é–¾å€¼
ALERT_THRESHOLD_CPU = 80.0
ALERT_THRESHOLD_MEMORY = 90.0
ALERT_THRESHOLD_DISK = 85.0

# ç›£æ§æœå‹™é…ç½®
MONITORED_SERVICES = [
    {
        'name': 'éœ€æ±‚åˆ†ææœå‹™',
        'url': 'http://localhost:5000/health',
        'port': 5000,
        'description': 'éœ€æ±‚åˆ†æUIå¾Œç«¯æœå‹™'
    },
    {
        'name': 'ä¸ƒå¤§å·¥ä½œæµæ¸¬è©¦ç³»çµ±',
        'url': 'http://localhost:5001/health',
        'port': 5001,
        'description': 'AICore0620 ä¸ƒå¤§å·¥ä½œæµæ¸¬è©¦ç³»çµ±'
    },
    {
        'name': 'ç™¼å¸ƒç®¡ç†æœå‹™',
        'url': 'http://localhost:5002/health',
        'port': 5002,
        'description': 'ç™¼å¸ƒç®¡ç†UIå¾Œç«¯æœå‹™'
    },
    {
        'name': 'æ¸¬è©¦ç®¡ç†å·¥ä½œæµMCP',
        'url': 'http://localhost:8321/health',
        'port': 8321,
        'description': 'æ¸¬è©¦ç®¡ç†å·¥ä½œæµMCPæœå‹™'
    },
    {
        'name': 'AIåˆ†æå¼•æ“',
        'url': 'http://localhost:8888/health',
        'port': 8888,
        'description': 'ç´”AIé©…å‹•åˆ†æç³»çµ±'
    },
    {
        'name': 'é‹ç‡Ÿå·¥ä½œæµMCP',
        'url': 'http://localhost:8091/health',
        'port': 8091,
        'description': 'é‹ç‡Ÿå·¥ä½œæµMCPæœå‹™'
    },
    {
        'name': 'é‹ç‡Ÿåˆ†æå¼•æ“',
        'url': 'http://localhost:8100/health',
        'port': 8100,
        'description': 'é‹ç‡Ÿåˆ†æå¼•æ“æœå‹™'
    }
]

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = MAX_CONTENT_LENGTH

# ç¢ºä¿ä¸Šå‚³ç›®éŒ„å­˜åœ¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

def init_database():
    """åˆå§‹åŒ–æ•¸æ“šåº«"""
    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()
    
    # å‰µå»ºå‘Šè­¦è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS alerts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            type TEXT NOT NULL,
            message TEXT NOT NULL,
            severity TEXT NOT NULL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            resolved BOOLEAN DEFAULT FALSE,
            resolved_at DATETIME
        )
    ''')
    
    # å‰µå»ºç³»çµ±ç›£æ§è¨˜éŒ„è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS system_metrics (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            cpu_percent REAL,
            memory_percent REAL,
            disk_percent REAL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # å‰µå»ºæœå‹™ç‹€æ…‹è¨˜éŒ„è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS service_status (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            service_name TEXT NOT NULL,
            status TEXT NOT NULL,
            response_time REAL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()

def check_service_health(service: Dict) -> Dict:
    """æª¢æŸ¥å–®å€‹æœå‹™å¥åº·ç‹€æ…‹"""
    try:
        start_time = time.time()
        response = requests.get(service['url'], timeout=5)
        response_time = time.time() - start_time
        
        if response.status_code == 200:
            return {
                'name': service['name'],
                'status': 'running',
                'response_time': round(response_time, 3),
                'port': service['port'],
                'description': service['description'],
                'details': response.json() if response.headers.get('content-type', '').startswith('application/json') else None
            }
        else:
            return {
                'name': service['name'],
                'status': 'error',
                'response_time': None,
                'port': service['port'],
                'description': service['description'],
                'details': {'error': f'HTTP {response.status_code}'}
            }
    except requests.exceptions.ConnectionError:
        return {
            'name': service['name'],
            'status': 'error',
            'response_time': None,
            'port': service['port'],
            'description': service['description'],
            'details': {'error': 'é€£æ¥è¢«æ‹’çµ•'}
        }
    except requests.exceptions.Timeout:
        return {
            'name': service['name'],
            'status': 'warning',
            'response_time': None,
            'port': service['port'],
            'description': service['description'],
            'details': {'error': 'è«‹æ±‚è¶…æ™‚'}
        }
    except Exception as e:
        return {
            'name': service['name'],
            'status': 'error',
            'response_time': None,
            'port': service['port'],
            'description': service['description'],
            'details': {'error': str(e)}
        }

def get_system_resources() -> Dict:
    """ç²å–ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³"""
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            'cpu_percent': round(cpu_percent, 1),
            'memory_percent': round(memory.percent, 1),
            'disk_percent': round(disk.percent, 1),
            'memory_total': round(memory.total / (1024**3), 2),  # GB
            'memory_used': round(memory.used / (1024**3), 2),   # GB
            'disk_total': round(disk.total / (1024**3), 2),     # GB
            'disk_used': round(disk.used / (1024**3), 2)        # GB
        }
    except Exception as e:
        logger.error(f"ç²å–ç³»çµ±è³‡æºå¤±æ•—: {e}")
        return {
            'cpu_percent': 0,
            'memory_percent': 0,
            'disk_percent': 0,
            'memory_total': 0,
            'memory_used': 0,
            'disk_total': 0,
            'disk_used': 0
        }

def create_alert(alert_type: str, message: str, severity: str = 'warning'):
    """å‰µå»ºå‘Šè­¦"""
    try:
        conn = sqlite3.connect(DATABASE_FILE)
        cursor = conn.cursor()
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„æœªè§£æ±ºå‘Šè­¦
        cursor.execute('''
            SELECT id FROM alerts 
            WHERE type = ? AND message = ? AND resolved = FALSE
        ''', (alert_type, message))
        
        if not cursor.fetchone():
            cursor.execute('''
                INSERT INTO alerts (type, message, severity)
                VALUES (?, ?, ?)
            ''', (alert_type, message, severity))
            conn.commit()
            logger.info(f"å‰µå»ºå‘Šè­¦: {alert_type} - {message}")
        
        conn.close()
    except Exception as e:
        logger.error(f"å‰µå»ºå‘Šè­¦å¤±æ•—: {e}")

def monitor_system():
    """ç³»çµ±ç›£æ§ç·šç¨‹"""
    while True:
        try:
            # ç²å–ç³»çµ±è³‡æº
            resources = get_system_resources()
            
            # è¨˜éŒ„åˆ°æ•¸æ“šåº«
            conn = sqlite3.connect(DATABASE_FILE)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO system_metrics (cpu_percent, memory_percent, disk_percent)
                VALUES (?, ?, ?)
            ''', (resources['cpu_percent'], resources['memory_percent'], resources['disk_percent']))
            conn.commit()
            conn.close()
            
            # æª¢æŸ¥å‘Šè­¦æ¢ä»¶
            if resources['cpu_percent'] > ALERT_THRESHOLD_CPU:
                create_alert('ç³»çµ±å‘Šè­¦', f'CPUä½¿ç”¨ç‡éé«˜: {resources["cpu_percent"]}%', 'warning')
            
            if resources['memory_percent'] > ALERT_THRESHOLD_MEMORY:
                create_alert('ç³»çµ±å‘Šè­¦', f'è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {resources["memory_percent"]}%', 'critical')
            
            if resources['disk_percent'] > ALERT_THRESHOLD_DISK:
                create_alert('ç³»çµ±å‘Šè­¦', f'ç£ç¢Ÿä½¿ç”¨ç‡éé«˜: {resources["disk_percent"]}%', 'warning')
            
            # æª¢æŸ¥æœå‹™ç‹€æ…‹
            for service in MONITORED_SERVICES:
                status = check_service_health(service)
                
                # è¨˜éŒ„æœå‹™ç‹€æ…‹
                conn = sqlite3.connect(DATABASE_FILE)
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO service_status (service_name, status, response_time)
                    VALUES (?, ?, ?)
                ''', (status['name'], status['status'], status['response_time']))
                conn.commit()
                conn.close()
                
                # å‰µå»ºæœå‹™å‘Šè­¦
                if status['status'] == 'error':
                    error_msg = status['details'].get('error', 'æœªçŸ¥éŒ¯èª¤') if status['details'] else 'æœå‹™ä¸å¯ç”¨'
                    create_alert('æœå‹™å‘Šè­¦', f'{status["name"]}: {error_msg}', 'critical')
            
            time.sleep(30)  # 30ç§’æª¢æŸ¥ä¸€æ¬¡
            
        except Exception as e:
            logger.error(f"ç›£æ§ç·šç¨‹éŒ¯èª¤: {e}")
            time.sleep(30)

def allowed_file(filename):
    """æª¢æŸ¥æ–‡ä»¶é¡å‹æ˜¯å¦å…è¨±"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# ==================== ç³»çµ±ç›£æ§API ====================

@app.route('/')
def index():
    """ä¸»é """
    return send_from_directory('frontend', 'index.html')

@app.route('/<path:filename>')
def static_files(filename):
    """éœæ…‹æ–‡ä»¶"""
    return send_from_directory('frontend', filename)

@app.route('/health')
def health_check():
    """å¥åº·æª¢æŸ¥"""
    return jsonify({
        'service': 'operations_center_backend',
        'status': 'healthy',
        'version': '1.0',
        'description': 'é‹ç‡Ÿä¸­å¿ƒæ•´åˆå¾Œç«¯æœå‹™',
        'timestamp': datetime.now().isoformat(),
        'features': {
            'system_monitoring': True,
            'workflow_management': True,
            'service_management': True,
            'resource_monitoring': True,
            'alert_management': True,
            'file_upload': True
        }
    })

@app.route('/api/system/overview')
def system_overview():
    """ç³»çµ±æ¦‚è¦½"""
    try:
        # ç²å–æœå‹™ç‹€æ…‹
        services_status = []
        for service in MONITORED_SERVICES:
            status = check_service_health(service)
            services_status.append(status)
        
        active_services = len([s for s in services_status if s['status'] == 'running'])
        total_services = len(services_status)
        
        # ç²å–æ´»å‹•å‘Šè­¦æ•¸é‡
        conn = sqlite3.connect(DATABASE_FILE)
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM alerts WHERE resolved = FALSE')
        active_alerts = cursor.fetchone()[0]
        conn.close()
        
        # ç²å–ç³»çµ±é‹è¡Œæ™‚é–“
        boot_time = psutil.boot_time()
        uptime_seconds = time.time() - boot_time
        uptime_hours = int(uptime_seconds // 3600)
        uptime_days = uptime_hours // 24
        uptime_hours = uptime_hours % 24
        
        uptime_str = f"{uptime_days}å¤© {uptime_hours}å°æ™‚" if uptime_days > 0 else f"{uptime_hours}å°æ™‚"
        
        return jsonify({
            'status': 'healthy' if active_services > total_services * 0.5 else 'warning',
            'uptime': uptime_str,
            'active_services': active_services,
            'total_services': total_services,
            'active_alerts': active_alerts,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"ç³»çµ±æ¦‚è¦½APIéŒ¯èª¤: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/services/status')
def services_status():
    """æœå‹™ç‹€æ…‹æª¢æŸ¥"""
    try:
        services = []
        for service in MONITORED_SERVICES:
            status = check_service_health(service)
            services.append(status)
        
        return jsonify({
            'services': services,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"æœå‹™ç‹€æ…‹APIéŒ¯èª¤: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/system/resources')
def system_resources():
    """ç³»çµ±è³‡æºç›£æ§"""
    try:
        resources = get_system_resources()
        resources['timestamp'] = datetime.now().isoformat()
        return jsonify(resources)
    except Exception as e:
        logger.error(f"ç³»çµ±è³‡æºAPIéŒ¯èª¤: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/alerts')
def get_alerts():
    """ç²å–å‘Šè­¦åˆ—è¡¨"""
    try:
        conn = sqlite3.connect(DATABASE_FILE)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT type, message, severity, timestamp, resolved
            FROM alerts 
            ORDER BY timestamp DESC 
            LIMIT 50
        ''')
        
        alerts = []
        for row in cursor.fetchall():
            alerts.append({
                'type': row[0],
                'message': row[1],
                'severity': row[2],
                'timestamp': row[3],
                'resolved': bool(row[4])
            })
        
        conn.close()
        
        return jsonify({
            'alerts': alerts,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"å‘Šè­¦APIéŒ¯èª¤: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/alerts/resolve', methods=['POST'])
def resolve_alert():
    """è§£æ±ºå‘Šè­¦"""
    try:
        data = request.get_json()
        alert_id = data.get('alert_id')
        
        if not alert_id:
            return jsonify({'error': 'ç¼ºå°‘å‘Šè­¦ID'}), 400
        
        conn = sqlite3.connect(DATABASE_FILE)
        cursor = conn.cursor()
        cursor.execute('''
            UPDATE alerts 
            SET resolved = TRUE, resolved_at = CURRENT_TIMESTAMP
            WHERE id = ?
        ''', (alert_id,))
        conn.commit()
        conn.close()
        
        return jsonify({'success': True, 'message': 'å‘Šè­¦å·²è§£æ±º'})
    except Exception as e:
        logger.error(f"è§£æ±ºå‘Šè­¦APIéŒ¯èª¤: {e}")
        return jsonify({'error': str(e)}), 500

# ==================== å·¥ä½œæµç®¡ç†API ====================

@app.route('/api/workflow/analyze', methods=['POST'])
def analyze_workflow():
    """å·¥ä½œæµåˆ†æ"""
    try:
        data = request.get_json()
        requirement = data.get('requirement', '')
        model = data.get('model', 'pure_ai_engine')
        
        if not requirement:
            return jsonify({'error': 'ç¼ºå°‘éœ€æ±‚æè¿°'}), 400
        
        # æ¨¡æ“¬AIåˆ†æéç¨‹
        start_time = time.time()
        
        # é€™è£¡å¯ä»¥é›†æˆå¯¦éš›çš„AIåˆ†æå¼•æ“
        # ç›®å‰è¿”å›æ¨¡æ“¬çµæœ
        analysis_result = f"""
ğŸ” é‹ç‡Ÿå·¥ä½œæµåˆ†æå ±å‘Š

ğŸ“‹ éœ€æ±‚åˆ†æ:
{requirement}

ğŸ¯ åˆ†æçµæœ:
åŸºæ–¼æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘è­˜åˆ¥å‡ºä»¥ä¸‹é—œéµè¦é»ï¼š

1. æµç¨‹å„ªåŒ–æ©Ÿæœƒ
   - è­˜åˆ¥ç“¶é ¸ç’°ç¯€
   - è‡ªå‹•åŒ–æ½›åŠ›è©•ä¼°
   - æ•ˆç‡æå‡å»ºè­°

2. è³‡æºé…ç½®å»ºè­°
   - äººåŠ›è³‡æºå„ªåŒ–
   - æŠ€è¡“å·¥å…·æ•´åˆ
   - æˆæœ¬æ•ˆç›Šåˆ†æ

3. å¯¦æ–½è·¯ç·šåœ–
   - çŸ­æœŸæ”¹å–„æªæ–½
   - ä¸­æœŸå„ªåŒ–ç›®æ¨™
   - é•·æœŸæˆ°ç•¥è¦åŠƒ

ğŸš€ å»ºè­°è¡Œå‹•:
- å„ªå…ˆè™•ç†é«˜å½±éŸ¿ã€ä½æˆæœ¬çš„æ”¹å–„é …ç›®
- å»ºç«‹é—œéµç¸¾æ•ˆæŒ‡æ¨™(KPI)ç›£æ§é«”ç³»
- å®šæœŸè©•ä¼°å’Œèª¿æ•´å·¥ä½œæµç¨‹

ğŸ“Š é æœŸæ•ˆæœ:
- æ•ˆç‡æå‡: 15-25%
- æˆæœ¬é™ä½: 10-20%
- å®¢æˆ¶æ»¿æ„åº¦æå‡: 20-30%
        """
        
        processing_time = time.time() - start_time
        
        return jsonify({
            'success': True,
            'analysis': analysis_result,
            'model_used': model,
            'processing_time': processing_time,
            'confidence_score': 0.85,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"å·¥ä½œæµåˆ†æAPIéŒ¯èª¤: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/workflow/upload', methods=['POST'])
def upload_workflow_files():
    """ä¸Šå‚³å·¥ä½œæµæ–‡ä»¶"""
    try:
        if 'files' not in request.files:
            return jsonify({'error': 'æ²’æœ‰æ–‡ä»¶è¢«ä¸Šå‚³'}), 400
        
        files = request.files.getlist('files')
        requirement = request.form.get('requirement', 'è«‹åˆ†æä¸Šå‚³çš„å·¥ä½œæµæ–‡ä»¶')
        
        if not files or all(file.filename == '' for file in files):
            return jsonify({'error': 'æ²’æœ‰é¸æ“‡æ–‡ä»¶'}), 400
        
        uploaded_files = []
        for file in files:
            if file and allowed_file(file.filename):
                filename = f"{int(time.time())}_{file.filename}"
                filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                file.save(filepath)
                uploaded_files.append({
                    'filename': file.filename,
                    'saved_as': filename,
                    'size': os.path.getsize(filepath)
                })
        
        if not uploaded_files:
            return jsonify({'error': 'æ²’æœ‰æœ‰æ•ˆçš„æ–‡ä»¶è¢«ä¸Šå‚³'}), 400
        
        # æ¨¡æ“¬æ–‡ä»¶åˆ†æéç¨‹
        start_time = time.time()
        
        analysis_result = f"""
ğŸ“ æ–‡ä»¶åˆ†æå ±å‘Š

ğŸ“‹ ä¸Šå‚³æ–‡ä»¶:
{chr(10).join([f"- {f['filename']} ({f['size']} bytes)" for f in uploaded_files])}

ğŸ” åˆ†æéœ€æ±‚:
{requirement}

ğŸ“Š åˆ†æçµæœ:
åŸºæ–¼ä¸Šå‚³çš„æ–‡ä»¶ï¼Œæˆ‘é€²è¡Œäº†ä»¥ä¸‹åˆ†æï¼š

1. æ–‡ä»¶çµæ§‹åˆ†æ
   - æ–‡ä»¶é¡å‹åˆ†å¸ƒ
   - å…§å®¹çµ„ç¹”æ–¹å¼
   - æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥

2. å·¥ä½œæµç¨‹è­˜åˆ¥
   - é—œéµæµç¨‹æ­¥é©Ÿ
   - æ±ºç­–é»åˆ†æ
   - ç•°å¸¸è™•ç†æ©Ÿåˆ¶

3. å„ªåŒ–å»ºè­°
   - æµç¨‹ç°¡åŒ–æ©Ÿæœƒ
   - è‡ªå‹•åŒ–æ½›åŠ›
   - æ¨™æº–åŒ–å»ºè­°

ğŸ¯ é—œéµç™¼ç¾:
- è­˜åˆ¥å‡º {len(uploaded_files)} å€‹ç›¸é—œæ–‡ä»¶
- ç™¼ç¾ 3-5 å€‹ä¸»è¦å·¥ä½œæµç¨‹
- è­˜åˆ¥å‡º 2-3 å€‹å„ªåŒ–æ©Ÿæœƒ

ğŸ’¡ æ”¹å–„å»ºè­°:
- å»ºç«‹çµ±ä¸€çš„æ–‡ä»¶å‘½åè¦ç¯„
- å¯¦æ–½ç‰ˆæœ¬æ§åˆ¶æ©Ÿåˆ¶
- å„ªåŒ–æµç¨‹æ–‡æª”çµæ§‹
        """
        
        processing_time = time.time() - start_time
        
        return jsonify({
            'success': True,
            'analysis': analysis_result,
            'uploaded_files': uploaded_files,
            'processing_time': processing_time,
            'confidence_score': 0.78,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šå‚³APIéŒ¯èª¤: {e}")
        return jsonify({'error': str(e)}), 500

# åˆå§‹åŒ–
init_database()

# å•Ÿå‹•ç›£æ§ç·šç¨‹
monitor_thread = threading.Thread(target=monitor_system, daemon=True)
monitor_thread.start()
logger.info("ç›£æ§ç·šç¨‹å·²å•Ÿå‹•")

if __name__ == '__main__':
    logger.info("å•Ÿå‹•é‹ç‡Ÿä¸­å¿ƒæ•´åˆå¾Œç«¯æœå‹™...")
    app.run(host='0.0.0.0', port=5010, debug=False)

