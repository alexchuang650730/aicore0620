#!/usr/bin/env python3
"""
ä¸‰å±¤æ¼¸é€²å¼æ™ºèƒ½æ„åœ–åŒ¹é…å¼•æ“
æ¶æ§‹ï¼šæœå°‹å¼•æ“ â†’ å…­å¤§å·¥ä½œæµ â†’ KiloCode å…œåº•

ç¬¬ä¸€å±¤ï¼šCloud Search MCP (å…¥å£å±¤)
ç¬¬äºŒå±¤ï¼šSix Workflow MCPs (è™•ç†å±¤)  
ç¬¬ä¸‰å±¤ï¼šKiloCode MCP (å…œåº•å±¤)

ä½œè€…: PowerAutomation åœ˜éšŠ
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-06-18
"""

import asyncio
import json
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from enum import Enum
from dataclasses import dataclass

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("progressive_intent_matcher")

class ProcessingLayer(Enum):
    """è™•ç†å±¤ç´šæšèˆ‰"""
    SEARCH_ENGINE = "search_engine"      # ç¬¬ä¸€å±¤ï¼šæœå°‹å¼•æ“
    WORKFLOW_MCPS = "workflow_mcps"      # ç¬¬äºŒå±¤ï¼šå…­å¤§å·¥ä½œæµ
    KILOCODE_FALLBACK = "kilocode_fallback"  # ç¬¬ä¸‰å±¤ï¼šKiloCode å…œåº•

class WorkflowType(Enum):
    """å…­å¤§å·¥ä½œæµé¡å‹"""
    REQUIREMENTS_ANALYSIS = "requirements_analysis"
    ARCHITECTURE_DESIGN = "architecture_design"
    CODING_IMPLEMENTATION = "coding_implementation"
    TESTING_VALIDATION = "testing_validation"
    DEPLOYMENT_OPERATIONS = "deployment_operations"
    MAINTENANCE_SUPPORT = "maintenance_support"

@dataclass
class IntentAnalysisResult:
    """æ„åœ–åˆ†æçµæœ"""
    confidence: float
    recommended_layer: ProcessingLayer
    workflow_type: Optional[WorkflowType]
    reasoning: str
    search_keywords: List[str]
    complexity_score: float

class ProgressiveIntentMatcher:
    """ä¸‰å±¤æ¼¸é€²å¼æ™ºèƒ½æ„åœ–åŒ¹é…å¼•æ“"""
    
    def __init__(self):
        self.name = "ProgressiveIntentMatcher"
        
        # MCP å·¥å…·è¨»å†Šè¡¨
        self.mcp_tools = {
            # ç¬¬ä¸€å±¤ï¼šæœå°‹å¼•æ“
            "cloud_search_mcp": {
                "layer": ProcessingLayer.SEARCH_ENGINE,
                "capabilities": ["semantic_search", "knowledge_retrieval", "intent_analysis"],
                "confidence_threshold": 0.7,
                "status": "available"
            },
            
            # ç¬¬äºŒå±¤ï¼šå…­å¤§å·¥ä½œæµ MCP
            "requirements_analysis_mcp": {
                "layer": ProcessingLayer.WORKFLOW_MCPS,
                "workflow_type": WorkflowType.REQUIREMENTS_ANALYSIS,
                "capabilities": ["requirement_gathering", "stakeholder_analysis", "user_story_creation"],
                "confidence_threshold": 0.8,
                "status": "available"
            },
            "architecture_design_mcp": {
                "layer": ProcessingLayer.WORKFLOW_MCPS,
                "workflow_type": WorkflowType.ARCHITECTURE_DESIGN,
                "capabilities": ["system_design", "component_architecture", "technology_selection"],
                "confidence_threshold": 0.8,
                "status": "available"
            },
            "coding_implementation_mcp": {
                "layer": ProcessingLayer.WORKFLOW_MCPS,
                "workflow_type": WorkflowType.CODING_IMPLEMENTATION,
                "capabilities": ["code_generation", "algorithm_implementation", "framework_integration"],
                "confidence_threshold": 0.8,
                "status": "available"
            },
            "testing_validation_mcp": {
                "layer": ProcessingLayer.WORKFLOW_MCPS,
                "workflow_type": WorkflowType.TESTING_VALIDATION,
                "capabilities": ["test_design", "quality_assurance", "performance_testing"],
                "confidence_threshold": 0.8,
                "status": "available"
            },
            "deployment_operations_mcp": {
                "layer": ProcessingLayer.WORKFLOW_MCPS,
                "workflow_type": WorkflowType.DEPLOYMENT_OPERATIONS,
                "capabilities": ["deployment_automation", "infrastructure_management", "monitoring_setup"],
                "confidence_threshold": 0.8,
                "status": "available"
            },
            "maintenance_support_mcp": {
                "layer": ProcessingLayer.WORKFLOW_MCPS,
                "workflow_type": WorkflowType.MAINTENANCE_SUPPORT,
                "capabilities": ["bug_fixing", "performance_optimization", "feature_enhancement"],
                "confidence_threshold": 0.8,
                "status": "available"
            },
            
            # ç¬¬ä¸‰å±¤ï¼šKiloCode å…œåº•
            "kilocode_mcp": {
                "layer": ProcessingLayer.KILOCODE_FALLBACK,
                "capabilities": ["tool_creation", "custom_solution", "unlimited_problem_solving"],
                "confidence_threshold": 0.0,  # å…œåº•å±¤ï¼Œç¸½æ˜¯å¯ç”¨
                "status": "available"
            }
        }
        
        # è¼”åŠ©å·¥å…·
        self.auxiliary_tools = {
            "sequential_thinking_mcp": ["task_decomposition", "reflection_engine", "dependency_analysis"],
            "rl_srt_mcp": ["reinforcement_learning", "self_reinforcing_training", "adaptive_optimization"],
            "cloud_edge_data_mcp": ["data_processing", "model_training", "performance_monitoring"],
            "local_model_mcp": ["local_inference", "offline_processing", "privacy_protection"],
            "enhanced_smartui_mcp": ["ui_generation", "dynamic_adaptation", "user_experience"]
        }
        
        # è™•ç†çµ±è¨ˆ
        self.processing_stats = {
            "total_requests": 0,
            "layer_usage": {layer.value: 0 for layer in ProcessingLayer},
            "workflow_usage": {workflow.value: 0 for workflow in WorkflowType},
            "success_rate": 0.0,
            "average_processing_time": 0.0
        }
        
        logger.info("ä¸‰å±¤æ¼¸é€²å¼æ™ºèƒ½æ„åœ–åŒ¹é…å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    async def analyze_user_intent(self, user_input: str, context: Dict[str, Any] = None) -> IntentAnalysisResult:
        """åˆ†æç”¨æˆ¶æ„åœ–ï¼Œæ±ºå®šè™•ç†å±¤ç´š"""
        
        logger.info(f"é–‹å§‹åˆ†æç”¨æˆ¶æ„åœ–: {user_input}")
        
        # ä½¿ç”¨ Cloud Search MCP é€²è¡Œåˆæ­¥åˆ†æ
        search_result = await self._call_cloud_search_analysis(user_input, context)
        
        # åŸºæ–¼æœå°‹çµæœæ±ºå®šè™•ç†ç­–ç•¥
        if search_result["can_be_resolved_by_search"]:
            # ç¬¬ä¸€å±¤ï¼šæœå°‹å¼•æ“å¯ä»¥è§£æ±º
            return IntentAnalysisResult(
                confidence=search_result["confidence"],
                recommended_layer=ProcessingLayer.SEARCH_ENGINE,
                workflow_type=None,
                reasoning="å•é¡Œå¯ä»¥é€šéæœå°‹å’ŒçŸ¥è­˜æª¢ç´¢è§£æ±º",
                search_keywords=search_result["keywords"],
                complexity_score=search_result["complexity"]
            )
        
        elif search_result["requires_workflow_processing"]:
            # ç¬¬äºŒå±¤ï¼šéœ€è¦å·¥ä½œæµè™•ç†
            workflow_type = self._determine_workflow_type(search_result)
            return IntentAnalysisResult(
                confidence=search_result["confidence"],
                recommended_layer=ProcessingLayer.WORKFLOW_MCPS,
                workflow_type=workflow_type,
                reasoning=f"éœ€è¦ {workflow_type.value} å·¥ä½œæµè™•ç†",
                search_keywords=search_result["keywords"],
                complexity_score=search_result["complexity"]
            )
        
        else:
            # ç¬¬ä¸‰å±¤ï¼šKiloCode å…œåº•
            return IntentAnalysisResult(
                confidence=1.0,  # å…œåº•å±¤ç¸½æ˜¯æœ‰ä¿¡å¿ƒ
                recommended_layer=ProcessingLayer.KILOCODE_FALLBACK,
                workflow_type=None,
                reasoning="éœ€è¦å‰µå»ºæ–°å·¥å…·æˆ–è‡ªå®šç¾©è§£æ±ºæ–¹æ¡ˆ",
                search_keywords=search_result["keywords"],
                complexity_score=search_result["complexity"]
            )
    
    async def process_request(self, user_input: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """è™•ç†ç”¨æˆ¶è«‹æ±‚çš„ä¸»è¦æ–¹æ³•"""
        
        start_time = datetime.now()
        self.processing_stats["total_requests"] += 1
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šåˆ†æç”¨æˆ¶æ„åœ–
            intent_result = await self.analyze_user_intent(user_input, context)
            
            # ç¬¬äºŒæ­¥ï¼šæ ¹æ“šæ¨è–¦å±¤ç´šé€²è¡Œè™•ç†
            if intent_result.recommended_layer == ProcessingLayer.SEARCH_ENGINE:
                result = await self._process_with_search_engine(user_input, intent_result, context)
                
            elif intent_result.recommended_layer == ProcessingLayer.WORKFLOW_MCPS:
                result = await self._process_with_workflow_mcps(user_input, intent_result, context)
                
            else:  # KILOCODE_FALLBACK
                result = await self._process_with_kilocode_fallback(user_input, intent_result, context)
            
            # æ›´æ–°çµ±è¨ˆä¿¡æ¯
            self.processing_stats["layer_usage"][intent_result.recommended_layer.value] += 1
            if intent_result.workflow_type:
                self.processing_stats["workflow_usage"][intent_result.workflow_type.value] += 1
            
            # è¨ˆç®—è™•ç†æ™‚é–“
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "status": "success",
                "result": result,
                "processing_info": {
                    "layer_used": intent_result.recommended_layer.value,
                    "workflow_type": intent_result.workflow_type.value if intent_result.workflow_type else None,
                    "confidence": intent_result.confidence,
                    "reasoning": intent_result.reasoning,
                    "processing_time": processing_time
                }
            }
            
        except Exception as e:
            logger.error(f"è™•ç†è«‹æ±‚å¤±æ•—: {str(e)}")
            return {
                "status": "error",
                "message": f"è™•ç†å¤±æ•—: {str(e)}",
                "fallback_suggestion": "å»ºè­°ä½¿ç”¨ KiloCode å…œåº•è™•ç†"
            }
    
    async def _call_cloud_search_analysis(self, user_input: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """èª¿ç”¨ Cloud Search MCP é€²è¡Œæ„åœ–åˆ†æ"""
        
        # æ¨¡æ“¬ Cloud Search MCP èª¿ç”¨
        logger.info("èª¿ç”¨ Cloud Search MCP é€²è¡Œæ„åœ–åˆ†æ")
        
        # é€™è£¡æ‡‰è©²æ˜¯å¯¦éš›çš„ MCP èª¿ç”¨
        # ç›®å‰è¿”å›æ¨¡æ“¬çµæœ
        
        # ç°¡å–®çš„é—œéµè©åˆ†æä¾†æ±ºå®šè™•ç†ç­–ç•¥
        keywords = user_input.lower().split()
        
        # åˆ¤æ–·æ˜¯å¦å¯ä»¥é€šéæœå°‹è§£æ±º
        search_indicators = ["ä»€éº¼æ˜¯", "å¦‚ä½•", "ç‚ºä»€éº¼", "ä»‹ç´¹", "èªªæ˜", "è§£é‡‹"]
        can_search_resolve = any(indicator in user_input for indicator in search_indicators)
        
        # åˆ¤æ–·æ˜¯å¦éœ€è¦å·¥ä½œæµè™•ç†
        workflow_indicators = ["é–‹ç™¼", "å»ºç«‹", "å‰µå»º", "è¨­è¨ˆ", "å¯¦ç¾", "éƒ¨ç½²", "æ¸¬è©¦"]
        needs_workflow = any(indicator in user_input for indicator in workflow_indicators)
        
        # è¨ˆç®—è¤‡é›œåº¦
        complexity = len(keywords) / 10.0  # ç°¡å–®çš„è¤‡é›œåº¦è¨ˆç®—
        
        return {
            "can_be_resolved_by_search": can_search_resolve and not needs_workflow,
            "requires_workflow_processing": needs_workflow,
            "confidence": 0.8 if can_search_resolve or needs_workflow else 0.6,
            "keywords": keywords,
            "complexity": min(complexity, 1.0),
            "analysis_details": {
                "search_indicators_found": [ind for ind in search_indicators if ind in user_input],
                "workflow_indicators_found": [ind for ind in workflow_indicators if ind in user_input]
            }
        }
    
    def _determine_workflow_type(self, search_result: Dict[str, Any]) -> WorkflowType:
        """æ ¹æ“šæœå°‹çµæœæ±ºå®šå·¥ä½œæµé¡å‹"""
        
        keywords = " ".join(search_result["keywords"])
        
        # å·¥ä½œæµé—œéµè©æ˜ å°„
        workflow_keywords = {
            WorkflowType.REQUIREMENTS_ANALYSIS: ["éœ€æ±‚", "åˆ†æ", "ç”¨æˆ¶æ•…äº‹", "åŠŸèƒ½"],
            WorkflowType.ARCHITECTURE_DESIGN: ["æ¶æ§‹", "è¨­è¨ˆ", "ç³»çµ±", "çµ„ä»¶"],
            WorkflowType.CODING_IMPLEMENTATION: ["é–‹ç™¼", "ç·¨ç¢¼", "å¯¦ç¾", "ç¨‹å¼", "ä»£ç¢¼"],
            WorkflowType.TESTING_VALIDATION: ["æ¸¬è©¦", "é©—è­‰", "å“è³ª", "æª¢æŸ¥"],
            WorkflowType.DEPLOYMENT_OPERATIONS: ["éƒ¨ç½²", "ç™¼å¸ƒ", "é‹ç¶­", "ç›£æ§"],
            WorkflowType.MAINTENANCE_SUPPORT: ["ç¶­è­·", "ä¿®å¾©", "å„ªåŒ–", "æ”¯æ´"]
        }
        
        # è¨ˆç®—æ¯å€‹å·¥ä½œæµçš„åŒ¹é…åˆ†æ•¸
        scores = {}
        for workflow_type, workflow_keys in workflow_keywords.items():
            score = sum(1 for key in workflow_keys if key in keywords)
            scores[workflow_type] = score
        
        # è¿”å›åˆ†æ•¸æœ€é«˜çš„å·¥ä½œæµé¡å‹
        best_workflow = max(scores, key=scores.get)
        
        # å¦‚æœæ²’æœ‰æ˜ç¢ºåŒ¹é…ï¼Œé»˜èªä½¿ç”¨ç·¨ç¢¼å·¥ä½œæµ
        if scores[best_workflow] == 0:
            return WorkflowType.CODING_IMPLEMENTATION
        
        return best_workflow
    
    async def _process_with_search_engine(self, user_input: str, intent_result: IntentAnalysisResult, context: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨æœå°‹å¼•æ“è™•ç†è«‹æ±‚"""
        
        logger.info("ä½¿ç”¨ç¬¬ä¸€å±¤ï¼šæœå°‹å¼•æ“è™•ç†è«‹æ±‚")
        
        # èª¿ç”¨ Cloud Search MCP
        search_params = {
            "query": user_input,
            "keywords": intent_result.search_keywords,
            "context": context,
            "max_results": 10
        }
        
        # æ¨¡æ“¬æœå°‹çµæœ
        return {
            "layer": "search_engine",
            "search_results": [
                {"title": "ç›¸é—œæ–‡æª”1", "content": "æœå°‹åˆ°çš„ç›¸é—œå…§å®¹...", "relevance": 0.9},
                {"title": "ç›¸é—œæ–‡æª”2", "content": "æ›´å¤šç›¸é—œä¿¡æ¯...", "relevance": 0.8}
            ],
            "answer": f"æ ¹æ“šæœå°‹çµæœï¼Œé—œæ–¼ '{user_input}' çš„å›ç­”æ˜¯...",
            "confidence": intent_result.confidence
        }
    
    async def _process_with_workflow_mcps(self, user_input: str, intent_result: IntentAnalysisResult, context: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨å·¥ä½œæµ MCP è™•ç†è«‹æ±‚"""
        
        logger.info(f"ä½¿ç”¨ç¬¬äºŒå±¤ï¼š{intent_result.workflow_type.value} å·¥ä½œæµè™•ç†è«‹æ±‚")
        
        # ç²å–å°æ‡‰çš„å·¥ä½œæµ MCP
        workflow_mcp_name = f"{intent_result.workflow_type.value}_mcp"
        
        # èª¿ç”¨å°æ‡‰çš„å·¥ä½œæµ MCP
        workflow_params = {
            "task": user_input,
            "context": context,
            "workflow_type": intent_result.workflow_type.value,
            "auxiliary_tools": self._get_required_auxiliary_tools(intent_result.workflow_type)
        }
        
        # æ¨¡æ“¬å·¥ä½œæµè™•ç†çµæœ
        return {
            "layer": "workflow_mcps",
            "workflow_type": intent_result.workflow_type.value,
            "workflow_result": {
                "status": "completed",
                "deliverables": [
                    f"{intent_result.workflow_type.value} åˆ†æå ±å‘Š",
                    f"{intent_result.workflow_type.value} å¯¦æ–½æ–¹æ¡ˆ"
                ],
                "next_steps": ["é€²å…¥ä¸‹ä¸€å€‹å·¥ä½œæµéšæ®µ", "é€²è¡Œè³ªé‡æª¢æŸ¥"]
            },
            "confidence": intent_result.confidence
        }
    
    async def _process_with_kilocode_fallback(self, user_input: str, intent_result: IntentAnalysisResult, context: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ KiloCode å…œåº•è™•ç†è«‹æ±‚"""
        
        logger.info("ä½¿ç”¨ç¬¬ä¸‰å±¤ï¼šKiloCode å…œåº•è™•ç†è«‹æ±‚")
        
        # èª¿ç”¨ KiloCode MCP å‰µå»ºè‡ªå®šç¾©è§£æ±ºæ–¹æ¡ˆ
        kilocode_params = {
            "problem_description": user_input,
            "context": context,
            "complexity_score": intent_result.complexity_score,
            "previous_attempts": "å‰å…©å±¤ç„¡æ³•è§£æ±º",
            "create_new_tool": True
        }
        
        # æ¨¡æ“¬ KiloCode è™•ç†çµæœ
        return {
            "layer": "kilocode_fallback",
            "solution_type": "custom_tool_creation",
            "created_tools": [
                {
                    "tool_name": f"CustomSolution_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "description": f"ç‚º '{user_input}' å‰µå»ºçš„è‡ªå®šç¾©è§£æ±ºæ–¹æ¡ˆ",
                    "capabilities": ["å•é¡Œåˆ†æ", "è§£æ±ºæ–¹æ¡ˆç”Ÿæˆ", "çµæœé©—è­‰"]
                }
            ],
            "implementation_plan": [
                "åˆ†æå•é¡Œéœ€æ±‚",
                "è¨­è¨ˆè§£æ±ºæ–¹æ¡ˆæ¶æ§‹", 
                "å¯¦ç¾æ ¸å¿ƒåŠŸèƒ½",
                "æ¸¬è©¦å’Œå„ªåŒ–",
                "éƒ¨ç½²å’Œç›£æ§"
            ],
            "confidence": 1.0  # KiloCode ç¸½æ˜¯æœ‰ä¿¡å¿ƒè§£æ±ºå•é¡Œ
        }
    
    def _get_required_auxiliary_tools(self, workflow_type: WorkflowType) -> List[str]:
        """ç²å–å·¥ä½œæµæ‰€éœ€çš„è¼”åŠ©å·¥å…·"""
        
        # æ ¹æ“šå·¥ä½œæµé¡å‹è¿”å›æ‰€éœ€çš„è¼”åŠ©å·¥å…·
        tool_mapping = {
            WorkflowType.REQUIREMENTS_ANALYSIS: ["sequential_thinking_mcp", "cloud_search_mcp"],
            WorkflowType.ARCHITECTURE_DESIGN: ["sequential_thinking_mcp", "enhanced_smartui_mcp"],
            WorkflowType.CODING_IMPLEMENTATION: ["local_model_mcp", "enhanced_smartui_mcp"],
            WorkflowType.TESTING_VALIDATION: ["cloud_edge_data_mcp", "rl_srt_mcp"],
            WorkflowType.DEPLOYMENT_OPERATIONS: ["cloud_edge_data_mcp", "enhanced_smartui_mcp"],
            WorkflowType.MAINTENANCE_SUPPORT: ["rl_srt_mcp", "cloud_edge_data_mcp"]
        }
        
        return tool_mapping.get(workflow_type, [])
    
    def get_system_status(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±ç‹€æ…‹"""
        
        return {
            "system_name": self.name,
            "architecture": "ä¸‰å±¤æ¼¸é€²å¼è™•ç†",
            "layers": {
                "layer_1": "Cloud Search MCP (æœå°‹å¼•æ“)",
                "layer_2": "Six Workflow MCPs (å°ˆæ¥­å·¥ä½œæµ)",
                "layer_3": "KiloCode MCP (å…œåº•å‰µå»º)"
            },
            "available_mcps": len([mcp for mcp in self.mcp_tools.values() if mcp["status"] == "available"]),
            "processing_stats": self.processing_stats,
            "status": "operational"
        }

# æ¸¬è©¦å‡½æ•¸
async def test_progressive_intent_matcher():
    """æ¸¬è©¦ä¸‰å±¤æ¼¸é€²å¼æ„åœ–åŒ¹é…å¼•æ“"""
    
    matcher = ProgressiveIntentMatcher()
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        "ä»€éº¼æ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",  # æ‡‰è©²èµ°æœå°‹å¼•æ“
        "æˆ‘æƒ³é–‹ç™¼ä¸€å€‹è²ªåƒè›‡éŠæˆ²",  # æ‡‰è©²èµ°ç·¨ç¢¼å·¥ä½œæµ
        "å¹«æˆ‘å‰µå»ºä¸€å€‹å…¨æ–°çš„é‡å­è¨ˆç®—æ¨¡æ“¬å™¨"  # æ‡‰è©²èµ° KiloCode å…œåº•
    ]
    
    for i, test_input in enumerate(test_cases, 1):
        print(f"\n=== æ¸¬è©¦æ¡ˆä¾‹ {i}: {test_input} ===")
        
        result = await matcher.process_request(test_input)
        
        print(f"è™•ç†çµæœ: {result['status']}")
        print(f"ä½¿ç”¨å±¤ç´š: {result['processing_info']['layer_used']}")
        if result['processing_info']['workflow_type']:
            print(f"å·¥ä½œæµé¡å‹: {result['processing_info']['workflow_type']}")
        print(f"ä¿¡å¿ƒåº¦: {result['processing_info']['confidence']:.2f}")
        print(f"æ¨ç†: {result['processing_info']['reasoning']}")
        print(f"è™•ç†æ™‚é–“: {result['processing_info']['processing_time']:.3f}ç§’")
    
    # é¡¯ç¤ºç³»çµ±ç‹€æ…‹
    print(f"\n=== ç³»çµ±ç‹€æ…‹ ===")
    status = matcher.get_system_status()
    print(json.dumps(status, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    print("ğŸš€ ä¸‰å±¤æ¼¸é€²å¼æ™ºèƒ½æ„åœ–åŒ¹é…å¼•æ“")
    print("æ¶æ§‹ï¼šæœå°‹å¼•æ“ â†’ å…­å¤§å·¥ä½œæµ â†’ KiloCode å…œåº•")
    print("=" * 50)
    
    asyncio.run(test_progressive_intent_matcher())

