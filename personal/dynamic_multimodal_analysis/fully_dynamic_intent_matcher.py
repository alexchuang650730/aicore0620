#!/usr/bin/env python3
"""
å®Œå…¨å‹•æ…‹è‡ªé©æ‡‰æ„åœ–åŒ¹é…å¼•æ“
Fully Dynamic Adaptive Intent Matching Engine

æ•´åˆæ‰€æœ‰ MCP tools çš„æ™ºèƒ½æ„åœ–åˆ†æç³»çµ±ï¼š
- rl_srt_mcp: å¼·åŒ–å­¸ç¿’è‡ªé©æ‡‰è¨“ç·´
- cloud_search_mcp: é›²ç«¯æœç´¢èƒ½åŠ›
- smart_tool_engine_mcp: æ™ºèƒ½å·¥å…·å¼•æ“
- å…¶ä»–æ‰€æœ‰å¯ç”¨çš„ MCP tools
"""

import asyncio
import json
import requests
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

@dataclass
class MCPToolRegistry:
    """MCP å·¥å…·è¨»å†Šè¡¨"""
    name: str
    endpoint: str
    capabilities: List[str]
    tool_type: str  # 'core', 'adapter', 'workflow', 'intelligence'
    priority: int = 1
    active: bool = True
    last_health_check: datetime = None
    
    def __post_init__(self):
        if self.last_health_check is None:
            self.last_health_check = datetime.now()

@dataclass
class AdaptiveLearningState:
    """è‡ªé©æ‡‰å­¸ç¿’ç‹€æ…‹"""
    pattern_weights: Dict[str, float]
    success_history: List[Dict[str, Any]]
    failure_patterns: List[Dict[str, Any]]
    learning_rate: float = 0.1
    confidence_threshold: float = 0.7
    last_update: datetime = None
    
    def __post_init__(self):
        if self.last_update is None:
            self.last_update = datetime.now()

@dataclass
class IntentMatchingResult:
    """æ„åœ–åŒ¹é…çµæœ"""
    user_input: str
    matched_workflow: str
    recommended_adapters: List[str]
    confidence_score: float
    reasoning: str
    required_capabilities: List[str]
    learning_feedback: Dict[str, Any]
    tool_chain: List[str]  # ä½¿ç”¨çš„å·¥å…·éˆ
    analysis_metadata: Dict[str, Any]

class FullyDynamicIntentMatcher:
    """
    å®Œå…¨å‹•æ…‹è‡ªé©æ‡‰æ„åœ–åŒ¹é…å¼•æ“
    
    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. è‡ªå‹•ç™¼ç¾å’Œè¨»å†Šæ‰€æœ‰ MCP tools
    2. åˆ©ç”¨ rl_srt é€²è¡Œå¼·åŒ–å­¸ç¿’
    3. ä½¿ç”¨ cloud_search é€²è¡Œæ™ºèƒ½æœç´¢
    4. èª¿ç”¨ smart_tool_engine é€²è¡Œèªç¾©åˆ†æ
    5. å®Œå…¨å‹•æ…‹ï¼Œç„¡ç¡¬ç·¨ç¢¼è¦å‰‡
    6. è‡ªé©æ‡‰å­¸ç¿’å’ŒæŒçºŒå„ªåŒ–
    """
    
    def __init__(self):
        self.mcp_tools: Dict[str, MCPToolRegistry] = {}
        self.learning_state = AdaptiveLearningState(
            pattern_weights={},
            success_history=[],
            failure_patterns=[]
        )
        
        # æ ¸å¿ƒå·¥å…·ç«¯é»
        self.core_tools = {
            "rl_srt_mcp": "http://localhost:8096",
            "cloud_search_mcp": "http://localhost:8097", 
            "smart_tool_engine_mcp": "http://localhost:8099"
        }
        
        # å·¥ä½œæµç«¯é»
        self.workflow_endpoints = {
            "requirements_analysis_mcp": "http://localhost:8090",
            "architecture_design_mcp": "http://localhost:8091",
            "coding_workflow_mcp": "http://localhost:8092",
            "developer_flow_mcp": "http://localhost:8093",
            "release_manager_mcp": "http://localhost:8094",
            "operations_workflow_mcp": "http://localhost:8095"
        }
        
        # åˆå§‹åŒ–ç³»çµ±
        asyncio.create_task(self.initialize_system())
    
    async def initialize_system(self):
        """åˆå§‹åŒ–å®Œå…¨å‹•æ…‹ç³»çµ±"""
        logger.info("ğŸš€ åˆå§‹åŒ–å®Œå…¨å‹•æ…‹è‡ªé©æ‡‰æ„åœ–åŒ¹é…ç³»çµ±")
        
        # 1. è‡ªå‹•ç™¼ç¾æ‰€æœ‰ MCP tools
        await self.discover_all_mcp_tools()
        
        # 2. åˆå§‹åŒ–å¼·åŒ–å­¸ç¿’ç³»çµ±
        await self.initialize_rl_system()
        
        # 3. é©—è­‰æ ¸å¿ƒå·¥å…·é€£æ¥
        await self.verify_core_tools()
        
        # 4. è¼‰å…¥å­¸ç¿’ç‹€æ…‹
        await self.load_learning_state()
        
        logger.info("âœ… å®Œå…¨å‹•æ…‹è‡ªé©æ‡‰æ„åœ–åŒ¹é…ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    
    async def discover_all_mcp_tools(self):
        """è‡ªå‹•ç™¼ç¾æ‰€æœ‰ MCP tools"""
        logger.info("ğŸ” è‡ªå‹•ç™¼ç¾æ‰€æœ‰ MCP tools")
        
        # ç™¼ç¾æ ¸å¿ƒå·¥å…·
        for name, endpoint in self.core_tools.items():
            await self.register_mcp_tool(name, endpoint, "core", priority=10)
        
        # ç™¼ç¾å·¥ä½œæµå·¥å…·
        for name, endpoint in self.workflow_endpoints.items():
            await self.register_mcp_tool(name, endpoint, "workflow", priority=5)
        
        # å‹•æ…‹ç™¼ç¾å…¶ä»–å·¥å…·ï¼ˆé€šéç«¯å£æƒææˆ–æœå‹™ç™¼ç¾ï¼‰
        await self.discover_additional_tools()
        
        logger.info(f"ğŸ“‹ ç™¼ç¾ {len(self.mcp_tools)} å€‹ MCP tools")
    
    async def register_mcp_tool(self, name: str, endpoint: str, tool_type: str, priority: int = 1):
        """è¨»å†Š MCP å·¥å…·"""
        try:
            # å˜—è©¦ç²å–å·¥å…·èƒ½åŠ›
            capabilities = await self.query_tool_capabilities(endpoint)
            
            tool_registry = MCPToolRegistry(
                name=name,
                endpoint=endpoint,
                capabilities=capabilities,
                tool_type=tool_type,
                priority=priority,
                active=True
            )
            
            self.mcp_tools[name] = tool_registry
            logger.info(f"ğŸ“ è¨»å†Šå·¥å…·: {name} ({tool_type}) - {len(capabilities)} å€‹èƒ½åŠ›")
            
        except Exception as e:
            logger.debug(f"ç„¡æ³•è¨»å†Šå·¥å…· {name}: {e}")
    
    async def query_tool_capabilities(self, endpoint: str) -> List[str]:
        """æŸ¥è©¢å·¥å…·èƒ½åŠ›"""
        try:
            # å˜—è©¦æ¨™æº–èƒ½åŠ›æŸ¥è©¢æ¥å£
            response = requests.get(f"{endpoint}/api/capabilities", timeout=5)
            if response.status_code == 200:
                data = response.json()
                return data.get("capabilities", [])
        except:
            pass
        
        # å¦‚æœæ¨™æº–æ¥å£ä¸å¯ç”¨ï¼Œè¿”å›æ¨æ–·çš„èƒ½åŠ›
        return self.infer_tool_capabilities(endpoint)
    
    def infer_tool_capabilities(self, endpoint: str) -> List[str]:
        """æ¨æ–·å·¥å…·èƒ½åŠ›"""
        port = endpoint.split(":")[-1]
        
        # åŸºæ–¼ç«¯å£æ¨æ–·èƒ½åŠ›
        port_capabilities = {
            "8090": ["éœ€æ±‚åˆ†æ", "æŠ€è¡“æ–¹æ¡ˆç”Ÿæˆ", "æ¥­å‹™ç†è§£"],
            "8091": ["æ¶æ§‹è¨­è¨ˆ", "ç³»çµ±è¨­è¨ˆ", "æœ€ä½³å¯¦è¸æ¨è–¦"],
            "8092": ["ä»£ç¢¼ç”Ÿæˆ", "AIç·¨ç¨‹åŠ©æ‰‹", "æ™ºèƒ½ä»£ç¢¼è£œå…¨"],
            "8093": ["è‡ªå‹•åŒ–æ¸¬è©¦", "è³ªé‡ä¿éšœ", "æ™ºèƒ½ä»‹å…¥å”èª¿"],
            "8094": ["ä¸€éµéƒ¨ç½²", "ç’°å¢ƒç®¡ç†", "ç‰ˆæœ¬æ§åˆ¶"],
            "8095": ["æ€§èƒ½ç›£æ§", "å•é¡Œé è­¦", "é‹ç¶­ç®¡ç†"],
            "8096": ["å¼·åŒ–å­¸ç¿’", "è‡ªé©æ‡‰è¨“ç·´", "æ¨¡å¼è­˜åˆ¥"],
            "8097": ["é›²ç«¯æœç´¢", "æ™ºèƒ½æª¢ç´¢", "èªç¾©åˆ†æ"],
            "8099": ["æ™ºèƒ½å·¥å…·å¼•æ“", "è‡ªç„¶èªè¨€è™•ç†", "æ·±åº¦åˆ†æ"]
        }
        
        return port_capabilities.get(port, ["é€šç”¨å·¥å…·èƒ½åŠ›"])
    
    async def discover_additional_tools(self):
        """ç™¼ç¾é¡å¤–çš„å·¥å…·"""
        # é€™è£¡å¯ä»¥å¯¦ç¾æ›´è¤‡é›œçš„æœå‹™ç™¼ç¾æ©Ÿåˆ¶
        # ä¾‹å¦‚ï¼šConsulã€Eurekaã€Kubernetes Service Discovery ç­‰
        
        # ç°¡åŒ–ç‰ˆæœ¬ï¼šæƒæå¸¸ç”¨ç«¯å£ç¯„åœ
        additional_ports = range(8100, 8110)
        
        for port in additional_ports:
            endpoint = f"http://localhost:{port}"
            try:
                response = requests.get(f"{endpoint}/health", timeout=2)
                if response.status_code == 200:
                    tool_name = f"discovered_tool_{port}"
                    await self.register_mcp_tool(tool_name, endpoint, "adapter")
            except:
                continue
    
    async def initialize_rl_system(self):
        """åˆå§‹åŒ–å¼·åŒ–å­¸ç¿’ç³»çµ±"""
        if "rl_srt_mcp" in self.mcp_tools:
            try:
                # åˆå§‹åŒ– RL-SRT ç³»çµ±
                response = requests.post(
                    f"{self.core_tools['rl_srt_mcp']}/api/initialize",
                    json={
                        "learning_rate": self.learning_state.learning_rate,
                        "confidence_threshold": self.learning_state.confidence_threshold
                    },
                    timeout=10
                )
                
                if response.status_code == 200:
                    logger.info("ğŸ§  å¼·åŒ–å­¸ç¿’ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
                else:
                    logger.warning("âš ï¸ å¼·åŒ–å­¸ç¿’ç³»çµ±åˆå§‹åŒ–å¤±æ•—")
                    
            except Exception as e:
                logger.warning(f"å¼·åŒ–å­¸ç¿’ç³»çµ±é€£æ¥å¤±æ•—: {e}")
    
    async def verify_core_tools(self):
        """é©—è­‰æ ¸å¿ƒå·¥å…·é€£æ¥"""
        for tool_name, endpoint in self.core_tools.items():
            try:
                response = requests.get(f"{endpoint}/health", timeout=5)
                if response.status_code == 200:
                    logger.info(f"âœ… {tool_name} é€£æ¥æ­£å¸¸")
                else:
                    logger.warning(f"âš ï¸ {tool_name} é€£æ¥ç•°å¸¸")
            except Exception as e:
                logger.warning(f"âš ï¸ {tool_name} é€£æ¥å¤±æ•—: {e}")
    
    async def load_learning_state(self):
        """è¼‰å…¥å­¸ç¿’ç‹€æ…‹"""
        try:
            # å¾ rl_srt_mcp è¼‰å…¥å­¸ç¿’ç‹€æ…‹
            if "rl_srt_mcp" in self.mcp_tools:
                response = requests.get(
                    f"{self.core_tools['rl_srt_mcp']}/api/learning_state",
                    timeout=5
                )
                
                if response.status_code == 200:
                    state_data = response.json()
                    self.learning_state.pattern_weights = state_data.get("pattern_weights", {})
                    logger.info("ğŸ“š å­¸ç¿’ç‹€æ…‹è¼‰å…¥æˆåŠŸ")
                    
        except Exception as e:
            logger.info(f"ä½¿ç”¨é»˜èªå­¸ç¿’ç‹€æ…‹: {e}")
    
    async def analyze_intent_with_full_tools(self, user_input: str, context: Dict[str, Any] = None) -> IntentMatchingResult:
        """ä½¿ç”¨å®Œæ•´å·¥å…·éˆé€²è¡Œæ„åœ–åˆ†æ"""
        logger.info(f"ğŸ¯ ä½¿ç”¨å®Œæ•´å·¥å…·éˆåˆ†ææ„åœ–: {user_input}")
        
        tool_chain = []
        analysis_results = {}
        
        # 1. ä½¿ç”¨ cloud_search_mcp é€²è¡Œèªç¾©æœç´¢
        search_result = await self.analyze_with_cloud_search(user_input)
        if search_result:
            tool_chain.append("cloud_search_mcp")
            analysis_results["search"] = search_result
        
        # 2. ä½¿ç”¨ smart_tool_engine_mcp é€²è¡Œæ·±åº¦åˆ†æ
        smart_analysis = await self.analyze_with_smart_tool_engine(user_input, analysis_results)
        if smart_analysis:
            tool_chain.append("smart_tool_engine_mcp")
            analysis_results["smart_analysis"] = smart_analysis
        
        # 3. ä½¿ç”¨ rl_srt_mcp é€²è¡Œå¼·åŒ–å­¸ç¿’åˆ†æ
        rl_analysis = await self.analyze_with_rl_srt(user_input, analysis_results)
        if rl_analysis:
            tool_chain.append("rl_srt_mcp")
            analysis_results["rl_analysis"] = rl_analysis
        
        # 4. ç¶œåˆåˆ†æçµæœ
        final_result = await self.synthesize_analysis_results(user_input, analysis_results, tool_chain)
        
        # 5. è¨˜éŒ„å­¸ç¿’åé¥‹
        await self.record_learning_feedback(final_result)
        
        return final_result
    
    async def analyze_with_cloud_search(self, user_input: str) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨é›²ç«¯æœç´¢é€²è¡Œåˆ†æ"""
        try:
            if "cloud_search_mcp" not in self.mcp_tools:
                return None
            
            response = requests.post(
                f"{self.core_tools['cloud_search_mcp']}/api/semantic_search",
                json={
                    "query": user_input,
                    "search_type": "intent_analysis",
                    "max_results": 5
                },
                timeout=15
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info("ğŸ” é›²ç«¯æœç´¢åˆ†æå®Œæˆ")
                return result
                
        except Exception as e:
            logger.warning(f"é›²ç«¯æœç´¢åˆ†æå¤±æ•—: {e}")
        
        return None
    
    async def analyze_with_smart_tool_engine(self, user_input: str, previous_results: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨æ™ºèƒ½å·¥å…·å¼•æ“é€²è¡Œåˆ†æ"""
        try:
            if "smart_tool_engine_mcp" not in self.mcp_tools:
                return None
            
            # æ§‹å»ºåˆ†æè«‹æ±‚
            analysis_request = {
                "user_input": user_input,
                "available_tools": [tool.name for tool in self.mcp_tools.values()],
                "previous_analysis": previous_results,
                "analysis_type": "intent_matching"
            }
            
            response = requests.post(
                f"{self.core_tools['smart_tool_engine_mcp']}/api/analyze",
                json=analysis_request,
                timeout=20
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info("ğŸ§  æ™ºèƒ½å·¥å…·å¼•æ“åˆ†æå®Œæˆ")
                return result
                
        except Exception as e:
            logger.warning(f"æ™ºèƒ½å·¥å…·å¼•æ“åˆ†æå¤±æ•—: {e}")
        
        return None
    
    async def analyze_with_rl_srt(self, user_input: str, previous_results: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨å¼·åŒ–å­¸ç¿’é€²è¡Œåˆ†æ"""
        try:
            if "rl_srt_mcp" not in self.mcp_tools:
                return None
            
            # æ§‹å»ºå¼·åŒ–å­¸ç¿’è«‹æ±‚
            rl_request = {
                "input_text": user_input,
                "context": previous_results,
                "learning_mode": "adaptive",
                "pattern_weights": self.learning_state.pattern_weights
            }
            
            response = requests.post(
                f"{self.core_tools['rl_srt_mcp']}/api/analyze_pattern",
                json=rl_request,
                timeout=15
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info("ğŸ¯ å¼·åŒ–å­¸ç¿’åˆ†æå®Œæˆ")
                return result
                
        except Exception as e:
            logger.warning(f"å¼·åŒ–å­¸ç¿’åˆ†æå¤±æ•—: {e}")
        
        return None
    
    async def synthesize_analysis_results(self, user_input: str, analysis_results: Dict[str, Any], tool_chain: List[str]) -> IntentMatchingResult:
        """ç¶œåˆåˆ†æçµæœ"""
        
        # æå–å„å€‹åˆ†æçµæœ
        search_result = analysis_results.get("search", {})
        smart_analysis = analysis_results.get("smart_analysis", {})
        rl_analysis = analysis_results.get("rl_analysis", {})
        
        # ç¶œåˆæ¨è–¦å·¥ä½œæµ
        recommended_workflow = self.determine_best_workflow(search_result, smart_analysis, rl_analysis)
        
        # ç¶œåˆæ¨è–¦é©é…å™¨
        recommended_adapters = self.determine_best_adapters(user_input, recommended_workflow, analysis_results)
        
        # è¨ˆç®—ä¿¡å¿ƒåº¦
        confidence_score = self.calculate_confidence_score(analysis_results, tool_chain)
        
        # ç”Ÿæˆæ¨ç†èªªæ˜
        reasoning = self.generate_reasoning(analysis_results, tool_chain)
        
        # æå–æ‰€éœ€èƒ½åŠ›
        required_capabilities = self.extract_required_capabilities(analysis_results)
        
        return IntentMatchingResult(
            user_input=user_input,
            matched_workflow=recommended_workflow,
            recommended_adapters=recommended_adapters,
            confidence_score=confidence_score,
            reasoning=reasoning,
            required_capabilities=required_capabilities,
            learning_feedback={},
            tool_chain=tool_chain,
            analysis_metadata={
                "analysis_time": datetime.now().isoformat(),
                "tools_used": len(tool_chain),
                "analysis_depth": "full_dynamic"
            }
        )
    
    def determine_best_workflow(self, search_result: Dict, smart_analysis: Dict, rl_analysis: Dict) -> str:
        """ç¢ºå®šæœ€ä½³å·¥ä½œæµ"""
        
        # æ”¶é›†å„å€‹åˆ†æçš„å·¥ä½œæµæ¨è–¦
        workflow_votes = {}
        
        # å¾æœç´¢çµæœä¸­æå–
        if "recommended_workflow" in search_result:
            workflow = search_result["recommended_workflow"]
            workflow_votes[workflow] = workflow_votes.get(workflow, 0) + 2
        
        # å¾æ™ºèƒ½åˆ†æä¸­æå–
        if "recommended_workflow" in smart_analysis:
            workflow = smart_analysis["recommended_workflow"]
            workflow_votes[workflow] = workflow_votes.get(workflow, 0) + 3
        
        # å¾å¼·åŒ–å­¸ç¿’ä¸­æå–
        if "predicted_workflow" in rl_analysis:
            workflow = rl_analysis["predicted_workflow"]
            confidence = rl_analysis.get("confidence", 0.5)
            workflow_votes[workflow] = workflow_votes.get(workflow, 0) + (confidence * 4)
        
        # é¸æ“‡å¾—ç¥¨æœ€é«˜çš„å·¥ä½œæµ
        if workflow_votes:
            best_workflow = max(workflow_votes, key=workflow_votes.get)
            return best_workflow
        
        # é»˜èªå·¥ä½œæµ
        return "coding_workflow_mcp"
    
    def determine_best_adapters(self, user_input: str, workflow: str, analysis_results: Dict) -> List[str]:
        """ç¢ºå®šæœ€ä½³é©é…å™¨"""
        adapters = set()
        
        # å¾å„å€‹åˆ†æçµæœä¸­æ”¶é›†é©é…å™¨æ¨è–¦
        for result in analysis_results.values():
            if "recommended_adapters" in result:
                adapters.update(result["recommended_adapters"])
        
        # åŸºæ–¼å·¥ä½œæµæ·»åŠ é»˜èªé©é…å™¨
        workflow_adapters = {
            "coding_workflow_mcp": ["kilocode_mcp", "advanced_smartui"],
            "requirements_analysis_mcp": ["enhanced_workflow_mcp"],
            "architecture_design_mcp": ["enhanced_workflow_mcp"],
            "developer_flow_mcp": ["test_manage_mcp"],
            "release_manager_mcp": ["deployment_mcp", "github_mcp"],
            "operations_workflow_mcp": ["monitoring_mcp"]
        }
        
        if workflow in workflow_adapters:
            adapters.update(workflow_adapters[workflow])
        
        return list(adapters)
    
    def calculate_confidence_score(self, analysis_results: Dict, tool_chain: List[str]) -> float:
        """è¨ˆç®—ä¿¡å¿ƒåº¦åˆ†æ•¸"""
        
        # åŸºç¤ä¿¡å¿ƒåº¦
        base_confidence = 0.5
        
        # å·¥å…·ä½¿ç”¨åŠ æˆ
        tool_bonus = len(tool_chain) * 0.1
        
        # åˆ†æçµæœä¸€è‡´æ€§åŠ æˆ
        consistency_bonus = 0.0
        if len(analysis_results) > 1:
            # æª¢æŸ¥æ¨è–¦çš„ä¸€è‡´æ€§
            workflows = []
            for result in analysis_results.values():
                if "recommended_workflow" in result:
                    workflows.append(result["recommended_workflow"])
            
            if workflows and len(set(workflows)) == 1:
                consistency_bonus = 0.2
        
        # å¼·åŒ–å­¸ç¿’ä¿¡å¿ƒåº¦
        rl_confidence = 0.0
        if "rl_analysis" in analysis_results:
            rl_confidence = analysis_results["rl_analysis"].get("confidence", 0.0) * 0.3
        
        total_confidence = min(1.0, base_confidence + tool_bonus + consistency_bonus + rl_confidence)
        return total_confidence
    
    def generate_reasoning(self, analysis_results: Dict, tool_chain: List[str]) -> str:
        """ç”Ÿæˆæ¨ç†èªªæ˜"""
        reasoning_parts = []
        
        if "search" in analysis_results:
            reasoning_parts.append("åŸºæ–¼é›²ç«¯æœç´¢çš„èªç¾©åˆ†æ")
        
        if "smart_analysis" in analysis_results:
            reasoning_parts.append("æ™ºèƒ½å·¥å…·å¼•æ“çš„æ·±åº¦ç†è§£")
        
        if "rl_analysis" in analysis_results:
            reasoning_parts.append("å¼·åŒ–å­¸ç¿’çš„æ¨¡å¼è­˜åˆ¥")
        
        if reasoning_parts:
            return f"ç¶œåˆ {', '.join(reasoning_parts)} çš„çµæœé€²è¡Œæ¨è–¦"
        else:
            return "åŸºæ–¼æœ¬åœ°æ™ºèƒ½åˆ†æé€²è¡Œæ¨è–¦"
    
    def extract_required_capabilities(self, analysis_results: Dict) -> List[str]:
        """æå–æ‰€éœ€èƒ½åŠ›"""
        capabilities = set()
        
        for result in analysis_results.values():
            if "required_capabilities" in result:
                capabilities.update(result["required_capabilities"])
        
        return list(capabilities)
    
    async def record_learning_feedback(self, result: IntentMatchingResult):
        """è¨˜éŒ„å­¸ç¿’åé¥‹"""
        try:
            if "rl_srt_mcp" in self.mcp_tools:
                feedback_data = {
                    "user_input": result.user_input,
                    "predicted_workflow": result.matched_workflow,
                    "confidence": result.confidence_score,
                    "tool_chain": result.tool_chain,
                    "timestamp": datetime.now().isoformat()
                }
                
                requests.post(
                    f"{self.core_tools['rl_srt_mcp']}/api/record_feedback",
                    json=feedback_data,
                    timeout=5
                )
                
        except Exception as e:
            logger.debug(f"è¨˜éŒ„å­¸ç¿’åé¥‹å¤±æ•—: {e}")
    
    async def update_learning_from_user_feedback(self, user_input: str, actual_workflow: str, success: bool):
        """æ ¹æ“šç”¨æˆ¶åé¥‹æ›´æ–°å­¸ç¿’"""
        try:
            if "rl_srt_mcp" in self.mcp_tools:
                feedback_data = {
                    "user_input": user_input,
                    "actual_workflow": actual_workflow,
                    "success": success,
                    "timestamp": datetime.now().isoformat()
                }
                
                response = requests.post(
                    f"{self.core_tools['rl_srt_mcp']}/api/update_learning",
                    json=feedback_data,
                    timeout=10
                )
                
                if response.status_code == 200:
                    logger.info(f"ğŸ“š å­¸ç¿’æ›´æ–°æˆåŠŸ: {user_input} â†’ {actual_workflow} ({'æˆåŠŸ' if success else 'å¤±æ•—'})")
                    
        except Exception as e:
            logger.warning(f"å­¸ç¿’æ›´æ–°å¤±æ•—: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±ç‹€æ…‹"""
        active_tools = [tool for tool in self.mcp_tools.values() if tool.active]
        
        return {
            "total_tools": len(self.mcp_tools),
            "active_tools": len(active_tools),
            "core_tools": list(self.core_tools.keys()),
            "workflow_tools": list(self.workflow_endpoints.keys()),
            "learning_state": {
                "pattern_weights_count": len(self.learning_state.pattern_weights),
                "success_history_count": len(self.learning_state.success_history),
                "learning_rate": self.learning_state.learning_rate
            },
            "tool_registry": {
                tool.name: {
                    "type": tool.tool_type,
                    "capabilities": tool.capabilities,
                    "priority": tool.priority,
                    "active": tool.active
                }
                for tool in self.mcp_tools.values()
            },
            "last_updated": datetime.now().isoformat()
        }

# æ¸¬è©¦å’Œæ¼”ç¤ºä»£ç¢¼
async def test_fully_dynamic_intent_matcher():
    """æ¸¬è©¦å®Œå…¨å‹•æ…‹æ„åœ–åŒ¹é…å™¨"""
    matcher = FullyDynamicIntentMatcher()
    
    # ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
    await asyncio.sleep(3)
    
    print("ğŸ§ª æ¸¬è©¦å®Œå…¨å‹•æ…‹è‡ªé©æ‡‰æ„åœ–åŒ¹é…å™¨")
    
    # æ¸¬è©¦ç”¨ä¾‹
    test_cases = [
        "æˆ‘æƒ³é–‹ç™¼è²ªåƒè›‡éŠæˆ²",
        "å»ºç«‹ä¸€å€‹ React è³¼ç‰©è»Šæ‡‰ç”¨",
        "éœ€è¦åˆ†æç³»çµ±éœ€æ±‚ä¸¦è¨­è¨ˆæ¶æ§‹",
        "é€²è¡Œä»£ç¢¼æ¸¬è©¦å’Œè³ªé‡ä¿éšœ",
        "éƒ¨ç½²æ‡‰ç”¨åˆ°ç”Ÿç”¢ç’°å¢ƒä¸¦ç›£æ§",
        "é–‹ç™¼ä¸€å€‹èŠå¤©æ©Ÿå™¨äºº",
        "å»ºç«‹æ•¸æ“šå¯è¦–åŒ–å„€è¡¨æ¿",
        "è¨­è¨ˆå¾®æœå‹™æ¶æ§‹",
        "å¯¦ç¾ç”¨æˆ¶èªè­‰ç³»çµ±"
    ]
    
    print("\nğŸ¯ å®Œå…¨å‹•æ…‹æ„åœ–åˆ†ææ¸¬è©¦:")
    for user_input in test_cases:
        result = await matcher.analyze_intent_with_full_tools(user_input)
        
        print(f"\nè¼¸å…¥: '{user_input}'")
        print(f"  æ¨è–¦å·¥ä½œæµ: {result.matched_workflow}")
        print(f"  æ¨è–¦é©é…å™¨: {result.recommended_adapters}")
        print(f"  ä¿¡å¿ƒåº¦: {result.confidence_score:.2f}")
        print(f"  å·¥å…·éˆ: {' â†’ '.join(result.tool_chain)}")
        print(f"  æ¨ç†: {result.reasoning}")
        print(f"  æ‰€éœ€èƒ½åŠ›: {result.required_capabilities[:3]}...")
    
    # é¡¯ç¤ºç³»çµ±ç‹€æ…‹
    status = matcher.get_system_status()
    print(f"\nğŸ“Š ç³»çµ±ç‹€æ…‹:")
    print(f"  ç¸½å·¥å…·æ•¸: {status['total_tools']}")
    print(f"  æ´»èºå·¥å…·æ•¸: {status['active_tools']}")
    print(f"  æ ¸å¿ƒå·¥å…·: {status['core_tools']}")
    print(f"  å­¸ç¿’ç‹€æ…‹: {status['learning_state']}")

if __name__ == "__main__":
    asyncio.run(test_fully_dynamic_intent_matcher())

