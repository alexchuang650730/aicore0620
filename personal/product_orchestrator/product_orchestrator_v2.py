#!/usr/bin/env python3
"""
Product Orchestrator - åŸºäºç°æœ‰workflowå’Œadapteræ¶æ„

é€šè¿‡MCPCoordinatoråè°ƒå…­ä¸ªworkflowï¼Œæ¯ä¸ªworkflowä½¿ç”¨ç›¸åº”çš„mcpç»„ä»¶å®Œæˆä»»åŠ¡ï¼š

å…­å¤§å·¥ä½œæµæ˜ å°„ï¼š
1. ğŸ“‹ éœ€æ±‚åˆ†æ â†’ requirements_analysis_mcp (workflow) + requirement_analysis_mcp (adapter)
2. ğŸ—ï¸ æ¶æ„è®¾è®¡ â†’ architecture_design_mcp (workflow) + enhanced_workflow_mcp (adapter)
3. ğŸ’» ç¼–ç å®ç° â†’ coding_workflow_mcp (workflow) + code_generation_mcp + kilocode_mcp (adapter)
4. ğŸ§ª æµ‹è¯•éªŒè¯ â†’ developer_flow_mcp (workflow) + test_manage_mcp (adapter)
5. ğŸš€ éƒ¨ç½²å‘å¸ƒ â†’ release_manager_mcp (workflow) + deployment_mcp (adapter)
6. ğŸ“Š ç›‘æ§è¿ç»´ â†’ operations_workflow_mcp (workflow) + monitoring_mcp (adapter)
"""

import asyncio
import json
import time
import uuid
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict
from enum import Enum
import logging
import requests
from flask import Flask, request, jsonify
from flask_cors import CORS

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# 1. æ•°æ®ç»“æ„å®šä¹‰
# ============================================================================

class WorkflowType(Enum):
    """å…­å¤§å·¥ä½œæµç±»å‹ï¼ˆå¯¹åº”ç°æœ‰workflowç›®å½•ï¼‰"""
    REQUIREMENTS_ANALYSIS = "requirements_analysis_mcp"
    ARCHITECTURE_DESIGN = "architecture_design_mcp"
    CODING_WORKFLOW = "coding_workflow_mcp"
    DEVELOPER_FLOW = "developer_flow_mcp"  # æµ‹è¯•éªŒè¯
    RELEASE_MANAGER = "release_manager_mcp"
    OPERATIONS_WORKFLOW = "operations_workflow_mcp"

class WorkflowStatus(Enum):
    """å·¥ä½œæµçŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class ProductType(Enum):
    """äº§å“ç±»å‹"""
    WEB_APPLICATION = "web_application"
    MOBILE_APP = "mobile_app"
    API_SERVICE = "api_service"
    DESKTOP_APPLICATION = "desktop_application"
    GAME = "game"
    AI_MODEL = "ai_model"

@dataclass
class WorkflowMapping:
    """å·¥ä½œæµä¸MCPç»„ä»¶æ˜ å°„"""
    workflow_name: str
    workflow_port: int
    adapter_mcps: List[str]
    description: str
    estimated_duration: str

@dataclass
class ProductRequest:
    """äº§å“å¼€å‘è¯·æ±‚"""
    request_id: str
    user_id: str
    product_name: str
    product_type: ProductType
    description: str
    requirements: Dict[str, Any]
    priority: str = "normal"
    deadline: Optional[str] = None
    created_at: str = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now().isoformat()

@dataclass
class WorkflowTask:
    """å·¥ä½œæµä»»åŠ¡"""
    task_id: str
    workflow_type: WorkflowType
    status: WorkflowStatus
    input_data: Dict[str, Any]
    output_data: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    duration: Optional[float] = None
    workflow_url: Optional[str] = None

@dataclass
class ProductProject:
    """äº§å“é¡¹ç›®"""
    project_id: str
    request: ProductRequest
    workflows: List[WorkflowTask]
    current_workflow: Optional[WorkflowType] = None
    overall_status: WorkflowStatus = WorkflowStatus.PENDING
    progress: float = 0.0
    artifacts: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.artifacts is None:
            self.artifacts = {}

# ============================================================================
# 2. å·¥ä½œæµæ˜ å°„é…ç½®
# ============================================================================

class WorkflowMappingConfig:
    """å·¥ä½œæµæ˜ å°„é…ç½®"""
    
    @staticmethod
    def get_workflow_mappings() -> Dict[WorkflowType, WorkflowMapping]:
        """è·å–å·¥ä½œæµæ˜ å°„é…ç½®"""
        return {
            WorkflowType.REQUIREMENTS_ANALYSIS: WorkflowMapping(
                workflow_name="requirements_analysis_mcp",
                workflow_port=8090,
                adapter_mcps=["requirement_analysis_mcp", "enhanced_workflow_mcp"],
                description="ğŸ“‹ éœ€æ±‚åˆ†æ - AIç†è§£ä¸šåŠ¡éœ€æ±‚ï¼Œç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆ",
                estimated_duration="3-8åˆ†é’Ÿ"
            ),
            WorkflowType.ARCHITECTURE_DESIGN: WorkflowMapping(
                workflow_name="architecture_design_mcp",
                workflow_port=8091,
                adapter_mcps=["enhanced_workflow_mcp", "directory_structure_mcp"],
                description="ğŸ—ï¸ æ¶æ„è®¾è®¡ - æ™ºèƒ½æ¶æ„å»ºè®®ï¼Œæœ€ä½³å®è·µæ¨è",
                estimated_duration="5-12åˆ†é’Ÿ"
            ),
            WorkflowType.CODING_WORKFLOW: WorkflowMapping(
                workflow_name="coding_workflow_mcp",
                workflow_port=8092,
                adapter_mcps=["code_generation_mcp", "kilocode_mcp", "github_mcp"],
                description="ğŸ’» ç¼–ç å®ç° - AIç¼–ç¨‹åŠ©æ‰‹ï¼Œä»£ç è‡ªåŠ¨ç”Ÿæˆï¼Œæ™ºèƒ½ä»£ç è¡¥å…¨",
                estimated_duration="10-25åˆ†é’Ÿ"
            ),
            WorkflowType.DEVELOPER_FLOW: WorkflowMapping(
                workflow_name="developer_flow_mcp",
                workflow_port=8093,
                adapter_mcps=["test_manage_mcp", "development_intervention_mcp"],
                description="ğŸ§ª æµ‹è¯•éªŒè¯ - è‡ªåŠ¨åŒ–æµ‹è¯•ï¼Œè´¨é‡ä¿éšœï¼Œæ™ºèƒ½ä»‹å…¥åè°ƒ",
                estimated_duration="8-18åˆ†é’Ÿ"
            ),
            WorkflowType.RELEASE_MANAGER: WorkflowMapping(
                workflow_name="release_manager_mcp",
                workflow_port=8094,
                adapter_mcps=["deployment_mcp", "github_mcp"],
                description="ğŸš€ éƒ¨ç½²å‘å¸ƒ - ä¸€é”®éƒ¨ç½²ï¼Œç¯å¢ƒç®¡ç†ï¼Œç‰ˆæœ¬æ§åˆ¶",
                estimated_duration="6-15åˆ†é’Ÿ"
            ),
            WorkflowType.OPERATIONS_WORKFLOW: WorkflowMapping(
                workflow_name="operations_workflow_mcp",
                workflow_port=8095,
                adapter_mcps=["monitoring_mcp", "enterprise_smartui_mcp"],
                description="ğŸ“Š ç›‘æ§è¿ç»´ - æ€§èƒ½ç›‘æ§ï¼Œé—®é¢˜é¢„è­¦",
                estimated_duration="4-10åˆ†é’Ÿ"
            )
        }

# ============================================================================
# 3. MCPCoordinatoré›†æˆå®¢æˆ·ç«¯
# ============================================================================

class MCPCoordinatorClient:
    """MCPCoordinatoré›†æˆå®¢æˆ·ç«¯"""
    
    def __init__(self, coordinator_url: str = "http://localhost:8089"):
        self.coordinator_url = coordinator_url
        self.session = requests.Session()
        
    async def send_workflow_request(self, workflow_type: WorkflowType, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """å‘æŒ‡å®šworkflowå‘é€è¯·æ±‚"""
        try:
            mapping = WorkflowMappingConfig.get_workflow_mappings()[workflow_type]
            workflow_url = f"http://localhost:{mapping.workflow_port}"
            
            # é¦–å…ˆå°è¯•ç›´æ¥è°ƒç”¨workflow
            try:
                response = self.session.post(
                    f"{workflow_url}/api/execute",
                    json=request_data,
                    timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
                )
                if response.status_code == 200:
                    return response.json()
            except Exception as e:
                logger.warning(f"ç›´æ¥è°ƒç”¨workflowå¤±è´¥ï¼Œå°è¯•é€šè¿‡MCPCoordinator: {e}")
            
            # å¦‚æœç›´æ¥è°ƒç”¨å¤±è´¥ï¼Œé€šè¿‡MCPCoordinator
            coordinator_payload = {
                "target_workflow": workflow_type.value,
                "action": "execute_workflow",
                "request_data": request_data,
                "timestamp": datetime.now().isoformat()
            }
            
            response = self.session.post(
                f"{self.coordinator_url}/api/workflow/execute",
                json=coordinator_payload,
                timeout=300
            )
            response.raise_for_status()
            
            return response.json()
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµè¯·æ±‚å¤±è´¥ {workflow_type.value}: {e}")
            return {"success": False, "error": str(e)}
    
    async def get_workflow_status(self, workflow_type: WorkflowType) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        try:
            mapping = WorkflowMappingConfig.get_workflow_mappings()[workflow_type]
            workflow_url = f"http://localhost:{mapping.workflow_port}"
            
            response = self.session.get(f"{workflow_url}/api/status", timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                # é€šè¿‡MCPCoordinatoræŸ¥è¯¢
                response = self.session.get(
                    f"{self.coordinator_url}/api/workflow/status/{workflow_type.value}",
                    timeout=10
                )
                response.raise_for_status()
                return response.json()
                
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥ {workflow_type.value}: {e}")
            return {"success": False, "error": str(e)}

# ============================================================================
# 4. å·¥ä½œæµæ‰§è¡Œå™¨
# ============================================================================

class WorkflowExecutor:
    """å·¥ä½œæµæ‰§è¡Œå™¨"""
    
    def __init__(self, mcp_coordinator: MCPCoordinatorClient):
        self.mcp_coordinator = mcp_coordinator
        self.workflow_mappings = WorkflowMappingConfig.get_workflow_mappings()
    
    async def execute_requirements_analysis(self, task: WorkflowTask) -> WorkflowTask:
        """æ‰§è¡Œéœ€æ±‚åˆ†æå·¥ä½œæµ"""
        logger.info(f"å¼€å§‹éœ€æ±‚åˆ†æ: {task.task_id}")
        
        task.status = WorkflowStatus.RUNNING
        task.started_at = datetime.now().isoformat()
        
        try:
            request_data = {
                "action": "analyze_requirements",
                "product_description": task.input_data.get("description", ""),
                "product_type": task.input_data.get("product_type", ""),
                "user_requirements": task.input_data.get("requirements", {}),
                "priority": task.input_data.get("priority", "normal")
            }
            
            result = await self.mcp_coordinator.send_workflow_request(
                WorkflowType.REQUIREMENTS_ANALYSIS,
                request_data
            )
            
            if result.get("success"):
                task.output_data = {
                    "technical_requirements": result.get("technical_requirements", {}),
                    "functional_requirements": result.get("functional_requirements", []),
                    "non_functional_requirements": result.get("non_functional_requirements", []),
                    "technology_stack_recommendations": result.get("technology_stack_recommendations", []),
                    "complexity_assessment": result.get("complexity_assessment", {}),
                    "risk_analysis": result.get("risk_analysis", []),
                    "timeline_estimate": result.get("timeline_estimate", ""),
                    "resource_requirements": result.get("resource_requirements", {})
                }
                task.status = WorkflowStatus.COMPLETED
                logger.info(f"éœ€æ±‚åˆ†æå®Œæˆ: {task.task_id}")
            else:
                task.status = WorkflowStatus.FAILED
                task.error_message = result.get("error", "éœ€æ±‚åˆ†æå¤±è´¥")
                
        except Exception as e:
            task.status = WorkflowStatus.FAILED
            task.error_message = str(e)
            logger.error(f"éœ€æ±‚åˆ†ææ‰§è¡Œå¼‚å¸¸: {e}")
        
        task.completed_at = datetime.now().isoformat()
        return task
    
    async def execute_architecture_design(self, task: WorkflowTask) -> WorkflowTask:
        """æ‰§è¡Œæ¶æ„è®¾è®¡å·¥ä½œæµ"""
        logger.info(f"å¼€å§‹æ¶æ„è®¾è®¡: {task.task_id}")
        
        task.status = WorkflowStatus.RUNNING
        task.started_at = datetime.now().isoformat()
        
        try:
            request_data = {
                "action": "design_architecture",
                "technical_requirements": task.input_data.get("technical_requirements", {}),
                "functional_requirements": task.input_data.get("functional_requirements", []),
                "technology_stack_recommendations": task.input_data.get("technology_stack_recommendations", []),
                "complexity_assessment": task.input_data.get("complexity_assessment", {}),
                "constraints": task.input_data.get("constraints", {})
            }
            
            result = await self.mcp_coordinator.send_workflow_request(
                WorkflowType.ARCHITECTURE_DESIGN,
                request_data
            )
            
            if result.get("success"):
                task.output_data = {
                    "system_architecture": result.get("system_architecture", {}),
                    "technology_stack": result.get("technology_stack", {}),
                    "database_design": result.get("database_design", {}),
                    "api_specifications": result.get("api_specifications", {}),
                    "deployment_architecture": result.get("deployment_architecture", {}),
                    "security_architecture": result.get("security_architecture", {}),
                    "scalability_plan": result.get("scalability_plan", {}),
                    "architecture_diagrams": result.get("architecture_diagrams", [])
                }
                task.status = WorkflowStatus.COMPLETED
                logger.info(f"æ¶æ„è®¾è®¡å®Œæˆ: {task.task_id}")
            else:
                task.status = WorkflowStatus.FAILED
                task.error_message = result.get("error", "æ¶æ„è®¾è®¡å¤±è´¥")
                
        except Exception as e:
            task.status = WorkflowStatus.FAILED
            task.error_message = str(e)
            logger.error(f"æ¶æ„è®¾è®¡æ‰§è¡Œå¼‚å¸¸: {e}")
        
        task.completed_at = datetime.now().isoformat()
        return task
    
    async def execute_coding_workflow(self, task: WorkflowTask) -> WorkflowTask:
        """æ‰§è¡Œç¼–ç å·¥ä½œæµ"""
        logger.info(f"å¼€å§‹ç¼–ç å®ç°: {task.task_id}")
        
        task.status = WorkflowStatus.RUNNING
        task.started_at = datetime.now().isoformat()
        
        try:
            request_data = {
                "action": "generate_code",
                "system_architecture": task.input_data.get("system_architecture", {}),
                "technology_stack": task.input_data.get("technology_stack", {}),
                "api_specifications": task.input_data.get("api_specifications", {}),
                "database_design": task.input_data.get("database_design", {}),
                "functional_requirements": task.input_data.get("functional_requirements", []),
                "coding_standards": task.input_data.get("coding_standards", {})
            }
            
            result = await self.mcp_coordinator.send_workflow_request(
                WorkflowType.CODING_WORKFLOW,
                request_data
            )
            
            if result.get("success"):
                task.output_data = {
                    "source_code": result.get("source_code", {}),
                    "project_structure": result.get("project_structure", {}),
                    "frontend_code": result.get("frontend_code", {}),
                    "backend_code": result.get("backend_code", {}),
                    "database_scripts": result.get("database_scripts", {}),
                    "configuration_files": result.get("configuration_files", {}),
                    "documentation": result.get("documentation", {}),
                    "build_scripts": result.get("build_scripts", {}),
                    "code_quality_metrics": result.get("code_quality_metrics", {}),
                    "repository_url": result.get("repository_url", "")
                }
                task.status = WorkflowStatus.COMPLETED
                logger.info(f"ç¼–ç å®ç°å®Œæˆ: {task.task_id}")
            else:
                task.status = WorkflowStatus.FAILED
                task.error_message = result.get("error", "ç¼–ç å®ç°å¤±è´¥")
                
        except Exception as e:
            task.status = WorkflowStatus.FAILED
            task.error_message = str(e)
            logger.error(f"ç¼–ç å®ç°æ‰§è¡Œå¼‚å¸¸: {e}")
        
        task.completed_at = datetime.now().isoformat()
        return task
    
    async def execute_developer_flow(self, task: WorkflowTask) -> WorkflowTask:
        """æ‰§è¡Œæµ‹è¯•éªŒè¯å·¥ä½œæµ"""
        logger.info(f"å¼€å§‹æµ‹è¯•éªŒè¯: {task.task_id}")
        
        task.status = WorkflowStatus.RUNNING
        task.started_at = datetime.now().isoformat()
        
        try:
            request_data = {
                "action": "run_tests",
                "source_code": task.input_data.get("source_code", {}),
                "functional_requirements": task.input_data.get("functional_requirements", []),
                "api_specifications": task.input_data.get("api_specifications", {}),
                "test_requirements": task.input_data.get("test_requirements", {}),
                "quality_standards": task.input_data.get("quality_standards", {})
            }
            
            result = await self.mcp_coordinator.send_workflow_request(
                WorkflowType.DEVELOPER_FLOW,
                request_data
            )
            
            if result.get("success"):
                task.output_data = {
                    "test_results": result.get("test_results", {}),
                    "test_coverage": result.get("test_coverage", 0),
                    "quality_metrics": result.get("quality_metrics", {}),
                    "performance_metrics": result.get("performance_metrics", {}),
                    "security_scan_results": result.get("security_scan_results", {}),
                    "issues_found": result.get("issues_found", []),
                    "recommendations": result.get("recommendations", []),
                    "test_reports": result.get("test_reports", []),
                    "quality_score": result.get("quality_score", 0),
                    "ready_for_deployment": result.get("ready_for_deployment", False)
                }
                task.status = WorkflowStatus.COMPLETED
                logger.info(f"æµ‹è¯•éªŒè¯å®Œæˆ: {task.task_id}")
            else:
                task.status = WorkflowStatus.FAILED
                task.error_message = result.get("error", "æµ‹è¯•éªŒè¯å¤±è´¥")
                
        except Exception as e:
            task.status = WorkflowStatus.FAILED
            task.error_message = str(e)
            logger.error(f"æµ‹è¯•éªŒè¯æ‰§è¡Œå¼‚å¸¸: {e}")
        
        task.completed_at = datetime.now().isoformat()
        return task
    
    async def execute_release_manager(self, task: WorkflowTask) -> WorkflowTask:
        """æ‰§è¡Œéƒ¨ç½²å‘å¸ƒå·¥ä½œæµ"""
        logger.info(f"å¼€å§‹éƒ¨ç½²å‘å¸ƒ: {task.task_id}")
        
        task.status = WorkflowStatus.RUNNING
        task.started_at = datetime.now().isoformat()
        
        try:
            request_data = {
                "action": "deploy_release",
                "source_code": task.input_data.get("source_code", {}),
                "deployment_architecture": task.input_data.get("deployment_architecture", {}),
                "configuration_files": task.input_data.get("configuration_files", {}),
                "test_results": task.input_data.get("test_results", {}),
                "ready_for_deployment": task.input_data.get("ready_for_deployment", False),
                "release_notes": task.input_data.get("release_notes", "")
            }
            
            result = await self.mcp_coordinator.send_workflow_request(
                WorkflowType.RELEASE_MANAGER,
                request_data
            )
            
            if result.get("success"):
                task.output_data = {
                    "deployment_url": result.get("deployment_url", ""),
                    "deployment_status": result.get("deployment_status", ""),
                    "environment_details": result.get("environment_details", {}),
                    "service_endpoints": result.get("service_endpoints", []),
                    "monitoring_urls": result.get("monitoring_urls", []),
                    "deployment_logs": result.get("deployment_logs", []),
                    "rollback_plan": result.get("rollback_plan", {}),
                    "performance_baseline": result.get("performance_baseline", {}),
                    "deployment_successful": result.get("deployment_successful", False),
                    "version_info": result.get("version_info", {})
                }
                task.status = WorkflowStatus.COMPLETED
                logger.info(f"éƒ¨ç½²å‘å¸ƒå®Œæˆ: {task.task_id}")
            else:
                task.status = WorkflowStatus.FAILED
                task.error_message = result.get("error", "éƒ¨ç½²å‘å¸ƒå¤±è´¥")
                
        except Exception as e:
            task.status = WorkflowStatus.FAILED
            task.error_message = str(e)
            logger.error(f"éƒ¨ç½²å‘å¸ƒæ‰§è¡Œå¼‚å¸¸: {e}")
        
        task.completed_at = datetime.now().isoformat()
        return task
    
    async def execute_operations_workflow(self, task: WorkflowTask) -> WorkflowTask:
        """æ‰§è¡Œç›‘æ§è¿ç»´å·¥ä½œæµ"""
        logger.info(f"å¼€å§‹ç›‘æ§è¿ç»´: {task.task_id}")
        
        task.status = WorkflowStatus.RUNNING
        task.started_at = datetime.now().isoformat()
        
        try:
            request_data = {
                "action": "setup_monitoring",
                "deployment_url": task.input_data.get("deployment_url", ""),
                "service_endpoints": task.input_data.get("service_endpoints", []),
                "environment_details": task.input_data.get("environment_details", {}),
                "performance_baseline": task.input_data.get("performance_baseline", {}),
                "monitoring_requirements": task.input_data.get("monitoring_requirements", {}),
                "alert_thresholds": task.input_data.get("alert_thresholds", {})
            }
            
            result = await self.mcp_coordinator.send_workflow_request(
                WorkflowType.OPERATIONS_WORKFLOW,
                request_data
            )
            
            if result.get("success"):
                task.output_data = {
                    "monitoring_dashboard": result.get("monitoring_dashboard", ""),
                    "alert_system": result.get("alert_system", {}),
                    "log_management": result.get("log_management", {}),
                    "performance_monitoring": result.get("performance_monitoring", {}),
                    "health_checks": result.get("health_checks", []),
                    "backup_strategy": result.get("backup_strategy", {}),
                    "disaster_recovery": result.get("disaster_recovery", {}),
                    "maintenance_procedures": result.get("maintenance_procedures", []),
                    "optimization_recommendations": result.get("optimization_recommendations", []),
                    "monitoring_active": result.get("monitoring_active", False)
                }
                task.status = WorkflowStatus.COMPLETED
                logger.info(f"ç›‘æ§è¿ç»´å®Œæˆ: {task.task_id}")
            else:
                task.status = WorkflowStatus.FAILED
                task.error_message = result.get("error", "ç›‘æ§è¿ç»´å¤±è´¥")
                
        except Exception as e:
            task.status = WorkflowStatus.FAILED
            task.error_message = str(e)
            logger.error(f"ç›‘æ§è¿ç»´æ‰§è¡Œå¼‚å¸¸: {e}")
        
        task.completed_at = datetime.now().isoformat()
        return task

# ============================================================================
# 5. äº§å“ç¼–æ’å™¨æ ¸å¿ƒ
# ============================================================================

class ProductOrchestrator:
    """äº§å“ç¼–æ’å™¨æ ¸å¿ƒ"""
    
    def __init__(self, coordinator_url: str = "http://localhost:8089"):
        self.mcp_coordinator = MCPCoordinatorClient(coordinator_url)
        self.workflow_executor = WorkflowExecutor(self.mcp_coordinator)
        self.projects: Dict[str, ProductProject] = {}
        self.workflow_mappings = WorkflowMappingConfig.get_workflow_mappings()
        
        # å·¥ä½œæµæ‰§è¡Œæ–¹æ³•æ˜ å°„
        self.workflow_executors = {
            WorkflowType.REQUIREMENTS_ANALYSIS: self.workflow_executor.execute_requirements_analysis,
            WorkflowType.ARCHITECTURE_DESIGN: self.workflow_executor.execute_architecture_design,
            WorkflowType.CODING_WORKFLOW: self.workflow_executor.execute_coding_workflow,
            WorkflowType.DEVELOPER_FLOW: self.workflow_executor.execute_developer_flow,
            WorkflowType.RELEASE_MANAGER: self.workflow_executor.execute_release_manager,
            WorkflowType.OPERATIONS_WORKFLOW: self.workflow_executor.execute_operations_workflow
        }
    
    async def create_product(self, product_request: ProductRequest) -> str:
        """åˆ›å»ºäº§å“å¼€å‘é¡¹ç›®"""
        project_id = str(uuid.uuid4())
        
        # åˆ›å»ºå·¥ä½œæµä»»åŠ¡åºåˆ—
        workflows = []
        for workflow_type in WorkflowType:
            task = WorkflowTask(
                task_id=f"{project_id}_{workflow_type.value}",
                workflow_type=workflow_type,
                status=WorkflowStatus.PENDING,
                input_data={},
                workflow_url=f"http://localhost:{self.workflow_mappings[workflow_type].workflow_port}"
            )
            workflows.append(task)
        
        # åˆ›å»ºé¡¹ç›®
        project = ProductProject(
            project_id=project_id,
            request=product_request,
            workflows=workflows,
            current_workflow=WorkflowType.REQUIREMENTS_ANALYSIS
        )
        
        self.projects[project_id] = project
        
        logger.info(f"åˆ›å»ºäº§å“é¡¹ç›®: {project_id} - {product_request.product_name}")
        return project_id
    
    async def execute_product_development(self, project_id: str) -> ProductProject:
        """æ‰§è¡Œå®Œæ•´çš„äº§å“å¼€å‘æµç¨‹"""
        if project_id not in self.projects:
            raise ValueError(f"é¡¹ç›®ä¸å­˜åœ¨: {project_id}")
        
        project = self.projects[project_id]
        project.overall_status = WorkflowStatus.RUNNING
        
        logger.info(f"å¼€å§‹æ‰§è¡Œäº§å“å¼€å‘æµç¨‹: {project_id}")
        
        try:
            # æŒ‰é¡ºåºæ‰§è¡Œå…­å¤§å·¥ä½œæµ
            workflow_sequence = list(WorkflowType)
            
            for i, workflow_type in enumerate(workflow_sequence):
                project.current_workflow = workflow_type
                task = next(w for w in project.workflows if w.workflow_type == workflow_type)
                
                logger.info(f"æ‰§è¡Œå·¥ä½œæµ {i+1}/6: {self.workflow_mappings[workflow_type].description}")
                
                # å‡†å¤‡è¾“å…¥æ•°æ®
                if i == 0:  # ç¬¬ä¸€ä¸ªå·¥ä½œæµï¼šéœ€æ±‚åˆ†æ
                    task.input_data = {
                        "description": project.request.description,
                        "product_type": project.request.product_type.value,
                        "requirements": project.request.requirements,
                        "priority": project.request.priority,
                        "deadline": project.request.deadline
                    }
                else:  # åç»­å·¥ä½œæµä½¿ç”¨å‰ä¸€ä¸ªå·¥ä½œæµçš„è¾“å‡º
                    prev_task = project.workflows[i-1]
                    if prev_task.output_data:
                        task.input_data.update(prev_task.output_data)
                    
                    # æ·»åŠ é¡¹ç›®åŸºæœ¬ä¿¡æ¯
                    task.input_data.update({
                        "project_id": project_id,
                        "product_name": project.request.product_name,
                        "product_type": project.request.product_type.value
                    })
                
                # æ‰§è¡Œå·¥ä½œæµ
                executor = self.workflow_executors[workflow_type]
                task = await executor(task)
                
                # æ›´æ–°é¡¹ç›®è¿›åº¦
                project.progress = (i + 1) / len(workflow_sequence) * 100
                
                # ä¿å­˜å·¥ä»¶
                if task.output_data:
                    project.artifacts[workflow_type.value] = task.output_data
                
                # å¦‚æœä»»åŠ¡å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ
                if task.status == WorkflowStatus.FAILED:
                    project.overall_status = WorkflowStatus.FAILED
                    logger.error(f"å·¥ä½œæµå¤±è´¥: {workflow_type.value}, é”™è¯¯: {task.error_message}")
                    break
                
                logger.info(f"å·¥ä½œæµå®Œæˆ {i+1}/6: {workflow_type.value}")
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å·¥ä½œæµéƒ½æˆåŠŸå®Œæˆ
            if all(w.status == WorkflowStatus.COMPLETED for w in project.workflows):
                project.overall_status = WorkflowStatus.COMPLETED
                project.progress = 100.0
                logger.info(f"ğŸ‰ äº§å“å¼€å‘å®Œæˆ: {project_id} - {project.request.product_name}")
            
        except Exception as e:
            project.overall_status = WorkflowStatus.FAILED
            logger.error(f"äº§å“å¼€å‘æ‰§è¡Œå¤±è´¥: {e}")
        
        return project
    
    def get_project_status(self, project_id: str) -> Optional[ProductProject]:
        """è·å–é¡¹ç›®çŠ¶æ€"""
        return self.projects.get(project_id)
    
    def list_projects(self) -> List[ProductProject]:
        """åˆ—å‡ºæ‰€æœ‰é¡¹ç›®"""
        return list(self.projects.values())
    
    def get_workflow_mappings(self) -> Dict[str, Dict[str, Any]]:
        """è·å–å·¥ä½œæµæ˜ å°„ä¿¡æ¯"""
        mappings = {}
        for workflow_type, mapping in self.workflow_mappings.items():
            mappings[workflow_type.value] = {
                "name": mapping.workflow_name,
                "port": mapping.workflow_port,
                "adapters": mapping.adapter_mcps,
                "description": mapping.description,
                "estimated_duration": mapping.estimated_duration
            }
        return mappings

# ============================================================================
# 6. Flask APIæœåŠ¡å™¨
# ============================================================================

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
CORS(app)

# åˆ›å»ºäº§å“ç¼–æ’å™¨å®ä¾‹
orchestrator = ProductOrchestrator()

@app.route('/health')
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "healthy",
        "service": "product_orchestrator",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat(),
        "workflow_mappings": orchestrator.get_workflow_mappings()
    })

@app.route('/api/workflows')
def get_workflows():
    """è·å–å·¥ä½œæµæ˜ å°„ä¿¡æ¯"""
    return jsonify({
        "success": True,
        "workflows": orchestrator.get_workflow_mappings()
    })

@app.route('/api/product/create', methods=['POST'])
def create_product():
    """åˆ›å»ºäº§å“"""
    try:
        data = request.get_json()
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['product_name', 'description']
        for field in required_fields:
            if not data.get(field):
                return jsonify({
                    "success": False,
                    "error": f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"
                }), 400
        
        # åˆ›å»ºäº§å“è¯·æ±‚
        product_request = ProductRequest(
            request_id=str(uuid.uuid4()),
            user_id=data.get('user_id', 'anonymous'),
            product_name=data.get('product_name'),
            product_type=ProductType(data.get('product_type', 'web_application')),
            description=data.get('description'),
            requirements=data.get('requirements', {}),
            priority=data.get('priority', 'normal'),
            deadline=data.get('deadline')
        )
        
        # åˆ›å»ºé¡¹ç›®
        project_id = asyncio.run(orchestrator.create_product(product_request))
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "message": f"äº§å“é¡¹ç›®åˆ›å»ºæˆåŠŸ: {product_request.product_name}",
            "workflows": orchestrator.get_workflow_mappings()
        })
        
    except Exception as e:
        logger.error(f"åˆ›å»ºäº§å“å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/product/develop/<project_id>', methods=['POST'])
def develop_product(project_id):
    """å¼€å§‹äº§å“å¼€å‘"""
    try:
        project = asyncio.run(orchestrator.execute_product_development(project_id))
        
        return jsonify({
            "success": True,
            "project": asdict(project),
            "message": "äº§å“å¼€å‘æµç¨‹æ‰§è¡Œå®Œæˆ"
        })
        
    except Exception as e:
        logger.error(f"äº§å“å¼€å‘å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/product/status/<project_id>')
def get_product_status(project_id):
    """è·å–äº§å“çŠ¶æ€"""
    try:
        project = orchestrator.get_project_status(project_id)
        
        if project:
            return jsonify({
                "success": True,
                "project": asdict(project)
            })
        else:
            return jsonify({
                "success": False,
                "error": "é¡¹ç›®ä¸å­˜åœ¨"
            }), 404
            
    except Exception as e:
        logger.error(f"è·å–äº§å“çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/products')
def list_products():
    """åˆ—å‡ºæ‰€æœ‰äº§å“"""
    try:
        projects = orchestrator.list_projects()
        
        return jsonify({
            "success": True,
            "projects": [asdict(p) for p in projects],
            "count": len(projects)
        })
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºäº§å“å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/product/quick-create', methods=['POST'])
def quick_create_product():
    """å¿«é€Ÿåˆ›å»ºå¹¶å¼€å‘äº§å“ï¼ˆç”¨äºSmartUIé›†æˆï¼‰"""
    try:
        data = request.get_json()
        
        # åˆ›å»ºäº§å“è¯·æ±‚
        product_request = ProductRequest(
            request_id=str(uuid.uuid4()),
            user_id=data.get('user_id', 'smartui_user'),
            product_name=data.get('product_name', 'æ™ºèƒ½ç”Ÿæˆäº§å“'),
            product_type=ProductType(data.get('product_type', 'web_application')),
            description=data.get('description', ''),
            requirements=data.get('requirements', {}),
            priority=data.get('priority', 'normal')
        )
        
        # åˆ›å»ºé¡¹ç›®
        project_id = await orchestrator.create_product(product_request)
        
        # ç«‹å³å¼€å§‹å¼€å‘
        project = await orchestrator.execute_product_development(project_id)
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "project": asdict(project),
            "message": "äº§å“å¿«é€Ÿåˆ›å»ºå’Œå¼€å‘å®Œæˆ"
        })
        
    except Exception as e:
        logger.error(f"å¿«é€Ÿåˆ›å»ºäº§å“å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

if __name__ == '__main__':
    logger.info("ğŸš€ å¯åŠ¨Product OrchestratoræœåŠ¡å™¨...")
    logger.info("ğŸ“‹ å·¥ä½œæµæ˜ å°„:")
    for workflow_type, mapping in WorkflowMappingConfig.get_workflow_mappings().items():
        logger.info(f"  {mapping.description}")
        logger.info(f"    ç«¯å£: {mapping.workflow_port}, é€‚é…å™¨: {', '.join(mapping.adapter_mcps)}")
    
    app.run(host='0.0.0.0', port=5002, debug=True)

