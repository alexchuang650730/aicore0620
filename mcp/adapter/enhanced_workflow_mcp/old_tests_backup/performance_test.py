#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºå‹å·¥ä½œæµå¼•æ“æ€§èƒ½æµ‹è¯•
Performance Test for Enhanced Workflow Engine

ä¸“é—¨ç”¨äºæ€§èƒ½æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•
"""

import asyncio
import time
import statistics
from typing import List, Dict, Any
from enhanced_workflow_engine import EnhancedWorkflowEngine
from dynamic_workflow_generator import DynamicWorkflowGenerator, WorkflowRequirement, WorkflowTemplate
from parallel_execution_scheduler import ParallelExecutionScheduler
from intelligent_dependency_manager import IntelligentDependencyManager, DependencyType, ConflictType
from workflow_state_manager import WorkflowStateManager

class PerformanceTest:
    """æ€§èƒ½æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.engine = EnhancedWorkflowEngine()
        self.generator = DynamicWorkflowGenerator()
        self.scheduler = ParallelExecutionScheduler()
        self.dependency_manager = IntelligentDependencyManager()
        self.state_manager = WorkflowStateManager()
        
        self.results = {}
    
    async def test_workflow_generation_performance(self, count: int = 100):
        """æµ‹è¯•å·¥ä½œæµç”Ÿæˆæ€§èƒ½"""
        print(f"ğŸš€ æµ‹è¯•å·¥ä½œæµç”Ÿæˆæ€§èƒ½ (ç”Ÿæˆ{count}ä¸ªå·¥ä½œæµ)...")
        
        times = []
        successful = 0
        
        for i in range(count):
            start_time = time.time()
            try:
                req = WorkflowRequirement(
                    name=f"æ€§èƒ½æµ‹è¯•å·¥ä½œæµ_{i}",
                    description=f"è¿™æ˜¯ç¬¬{i}ä¸ªæ€§èƒ½æµ‹è¯•å·¥ä½œæµ",
                    template=WorkflowTemplate.BASIC
                )
                
                workflow = await self.generator.generate_workflow(req)
                end_time = time.time()
                times.append(end_time - start_time)
                successful += 1
                
            except Exception as e:
                print(f"âŒ å·¥ä½œæµ{i}ç”Ÿæˆå¤±è´¥: {e}")
        
        if times:
            avg_time = statistics.mean(times)
            min_time = min(times)
            max_time = max(times)
            median_time = statistics.median(times)
            
            self.results['workflow_generation'] = {
                'count': count,
                'successful': successful,
                'success_rate': successful / count * 100,
                'avg_time': avg_time,
                'min_time': min_time,
                'max_time': max_time,
                'median_time': median_time,
                'total_time': sum(times)
            }
            
            print(f"âœ… å·¥ä½œæµç”Ÿæˆæ€§èƒ½æµ‹è¯•å®Œæˆ:")
            print(f"   æ€»æ•°é‡: {count}")
            print(f"   æˆåŠŸæ•°: {successful}")
            print(f"   æˆåŠŸç‡: {successful/count*100:.1f}%")
            print(f"   å¹³å‡æ—¶é—´: {avg_time:.4f}ç§’")
            print(f"   æœ€å°æ—¶é—´: {min_time:.4f}ç§’")
            print(f"   æœ€å¤§æ—¶é—´: {max_time:.4f}ç§’")
            print(f"   ä¸­ä½æ—¶é—´: {median_time:.4f}ç§’")
        else:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„å·¥ä½œæµç”Ÿæˆ")
    
    async def test_dependency_analysis_performance(self, node_count: int = 50):
        """æµ‹è¯•ä¾èµ–åˆ†ææ€§èƒ½"""
        print(f"ğŸ”— æµ‹è¯•ä¾èµ–åˆ†ææ€§èƒ½ (åˆ†æ{node_count}ä¸ªèŠ‚ç‚¹)...")
        
        # åˆ›å»ºæµ‹è¯•ä¾èµ–å…³ç³»
        start_time = time.time()
        
        # æ·»åŠ èŠ‚ç‚¹ (è‡ªåŠ¨æ·»åŠ åˆ°å›¾ä¸­)
        for i in range(node_count):
            node_id = f"node_{i}"
            # èŠ‚ç‚¹ä¼šåœ¨æ·»åŠ ä¾èµ–æ—¶è‡ªåŠ¨æ·»åŠ åˆ°å›¾ä¸­
        
        # æ·»åŠ ä¾èµ–å…³ç³» (åˆ›å»ºä¸€ä¸ªå¤æ‚çš„ä¾èµ–å›¾)
        for i in range(node_count - 1):
            await self.dependency_manager.add_dependency(f"node_{i}", f"node_{i+1}", DependencyType.DATA)
            
            # æ·»åŠ ä¸€äº›äº¤å‰ä¾èµ–
            if i % 3 == 0 and i + 3 < node_count:
                await self.dependency_manager.add_dependency(f"node_{i}", f"node_{i+3}", DependencyType.CONTROL)
        
        # æ‰§è¡Œæ‹“æ‰‘æ’åº
        topo_start = time.time()
        sorted_nodes = self.dependency_manager._calculate_topological_order()
        topo_end = time.time()
        
        # æ£€æµ‹å¾ªç¯ä¾èµ–
        cycle_start = time.time()
        conflicts = await self.dependency_manager._detect_conflicts()
        has_cycle = any(c.conflict_type == ConflictType.CIRCULAR_DEPENDENCY for c in conflicts)
        cycle_end = time.time()
        
        end_time = time.time()
        
        self.results['dependency_analysis'] = {
            'node_count': node_count,
            'total_time': end_time - start_time,
            'topo_sort_time': topo_end - topo_start,
            'cycle_detection_time': cycle_end - cycle_start,
            'sorted_nodes_count': len(sorted_nodes),
            'has_cycle': has_cycle
        }
        
        print(f"âœ… ä¾èµ–åˆ†ææ€§èƒ½æµ‹è¯•å®Œæˆ:")
        print(f"   èŠ‚ç‚¹æ•°é‡: {node_count}")
        print(f"   æ€»æ—¶é—´: {end_time - start_time:.4f}ç§’")
        print(f"   æ‹“æ‰‘æ’åº: {topo_end - topo_start:.4f}ç§’")
        print(f"   å¾ªç¯æ£€æµ‹: {cycle_end - cycle_start:.4f}ç§’")
        print(f"   æ’åºç»“æœ: {len(sorted_nodes)}ä¸ªèŠ‚ç‚¹")
    
    async def test_parallel_execution_performance(self, task_count: int = 20):
        """æµ‹è¯•å¹¶è¡Œæ‰§è¡Œæ€§èƒ½"""
        print(f"âš¡ æµ‹è¯•å¹¶è¡Œæ‰§è¡Œæ€§èƒ½ (æ‰§è¡Œ{task_count}ä¸ªä»»åŠ¡)...")
        
        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
        tasks = []
        for i in range(task_count):
            task = {
                'id': f'task_{i}',
                'type': 'test_task',
                'config': {'duration': 0.1, 'data': f'test_data_{i}'},
                'dependencies': []
            }
            tasks.append(task)
        
        # é¡ºåºæ‰§è¡Œæµ‹è¯•
        sequential_start = time.time()
        for task in tasks:
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
        sequential_end = time.time()
        sequential_time = sequential_end - sequential_start
        
        # å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
        parallel_start = time.time()
        parallel_tasks = [asyncio.sleep(0.1) for _ in range(task_count)]
        await asyncio.gather(*parallel_tasks)
        parallel_end = time.time()
        parallel_time = parallel_end - parallel_start
        
        speedup = sequential_time / parallel_time if parallel_time > 0 else 0
        
        self.results['parallel_execution'] = {
            'task_count': task_count,
            'sequential_time': sequential_time,
            'parallel_time': parallel_time,
            'speedup': speedup,
            'efficiency': speedup / task_count * 100
        }
        
        print(f"âœ… å¹¶è¡Œæ‰§è¡Œæ€§èƒ½æµ‹è¯•å®Œæˆ:")
        print(f"   ä»»åŠ¡æ•°é‡: {task_count}")
        print(f"   é¡ºåºæ‰§è¡Œ: {sequential_time:.4f}ç§’")
        print(f"   å¹¶è¡Œæ‰§è¡Œ: {parallel_time:.4f}ç§’")
        print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
        print(f"   æ•ˆç‡: {speedup/task_count*100:.1f}%")
    
    async def test_state_management_performance(self, operation_count: int = 1000):
        """æµ‹è¯•çŠ¶æ€ç®¡ç†æ€§èƒ½"""
        print(f"ğŸ’¾ æµ‹è¯•çŠ¶æ€ç®¡ç†æ€§èƒ½ (æ‰§è¡Œ{operation_count}æ¬¡æ“ä½œ)...")
        
        # åˆ›å»ºæµ‹è¯•å·¥ä½œæµ
        req = WorkflowRequirement(
            name="çŠ¶æ€æµ‹è¯•å·¥ä½œæµ",
            description="ç”¨äºçŠ¶æ€ç®¡ç†æ€§èƒ½æµ‹è¯•"
        )
        workflow = await self.generator.generate_workflow(req)
        
        # ä¿å­˜å·¥ä½œæµ
        save_start = time.time()
        self.state_manager.save_workflow_state(workflow.id, {
            'status': 'running',
            'progress': 0,
            'data': {'test': 'data'}
        })
        save_end = time.time()
        
        # æ‰¹é‡æ›´æ–°æµ‹è¯•
        update_times = []
        for i in range(operation_count):
            update_start = time.time()
            self.state_manager.update_workflow_state(workflow.id, {
                'progress': i / operation_count * 100,
                'current_step': f'step_{i}'
            })
            update_end = time.time()
            update_times.append(update_end - update_start)
        
        # æŸ¥è¯¢æµ‹è¯•
        query_start = time.time()
        for i in range(100):  # æŸ¥è¯¢100æ¬¡
            state = self.state_manager.get_workflow_state(workflow.id)
        query_end = time.time()
        
        avg_update_time = statistics.mean(update_times) if update_times else 0
        avg_query_time = (query_end - query_start) / 100
        
        self.results['state_management'] = {
            'operation_count': operation_count,
            'save_time': save_end - save_start,
            'avg_update_time': avg_update_time,
            'avg_query_time': avg_query_time,
            'total_update_time': sum(update_times)
        }
        
        print(f"âœ… çŠ¶æ€ç®¡ç†æ€§èƒ½æµ‹è¯•å®Œæˆ:")
        print(f"   æ“ä½œæ•°é‡: {operation_count}")
        print(f"   ä¿å­˜æ—¶é—´: {save_end - save_start:.4f}ç§’")
        print(f"   å¹³å‡æ›´æ–°: {avg_update_time:.6f}ç§’")
        print(f"   å¹³å‡æŸ¥è¯¢: {avg_query_time:.6f}ç§’")
    
    def print_summary(self):
        """æ‰“å°æ€§èƒ½æµ‹è¯•æ€»ç»“"""
        print("\n" + "="*60)
        print("ğŸ“Š æ€§èƒ½æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print("="*60)
        
        for test_name, result in self.results.items():
            print(f"\nğŸ¯ {test_name.replace('_', ' ').title()}:")
            for key, value in result.items():
                if isinstance(value, float):
                    if 'time' in key:
                        print(f"   {key}: {value:.4f}ç§’")
                    elif 'rate' in key or 'efficiency' in key:
                        print(f"   {key}: {value:.1f}%")
                    else:
                        print(f"   {key}: {value:.2f}")
                else:
                    print(f"   {key}: {value}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¢å¼ºå‹å·¥ä½œæµå¼•æ“æ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    perf_test = PerformanceTest()
    
    # è¿è¡Œå„é¡¹æ€§èƒ½æµ‹è¯•
    await perf_test.test_workflow_generation_performance(50)
    print()
    
    await perf_test.test_dependency_analysis_performance(30)
    print()
    
    await perf_test.test_parallel_execution_performance(10)
    print()
    
    await perf_test.test_state_management_performance(500)
    
    # æ‰“å°æ€»ç»“
    perf_test.print_summary()
    
    print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    asyncio.run(main())

