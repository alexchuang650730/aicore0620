#!/usr/bin/env python3
"""
éœ€æ±‚åˆ†ææ™ºèƒ½å¼•æ“ MCP
Requirements Analysis Intelligent Engine MCP

åŸºäºPowerAutoæ¶æ„çš„æ™ºèƒ½éœ€æ±‚åˆ†æå·¥ä½œæµ
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import toml
import yaml

# å¯¼å…¥åŸºç¡€å·¥ä½œæµç±»
import sys
sys.path.append(str(Path(__file__).parent.parent.parent.parent))
from workflow_howto.base_workflow import BaseWorkflow

class RequirementType(Enum):
    FUNCTIONAL = "functional"
    NON_FUNCTIONAL = "non_functional"
    TECHNICAL = "technical"
    BUSINESS = "business"

class ComplexityLevel(Enum):
    SIMPLE = "simple"
    MEDIUM = "medium"
    COMPLEX = "complex"

class DomainType(Enum):
    OCR = "ocr"
    NLP = "nlp"
    WEB = "web"
    AI = "ai"
    VISION = "vision"
    OTHER = "other"

@dataclass
class Requirement:
    id: str
    text: str
    type: RequirementType
    priority: int
    complexity: float
    dependencies: List[str]
    domain: DomainType
    confidence: float

@dataclass
class Solution:
    id: str
    title: str
    description: str
    technology_stack: List[str]
    estimated_effort: int  # äººå¤©
    confidence: float
    pros: List[str]
    cons: List[str]
    risks: List[str]
    implementation_steps: List[str]
    timeline_estimate: str
    cost_estimate: float

@dataclass
class FeasibilityReport:
    overall_feasibility: float
    technical_challenges: List[str]
    resource_requirements: Dict[str, Any]
    timeline_estimate: int
    risk_factors: List[str]
    confidence: float

@dataclass
class RequirementAnalysisRequest:
    requirement_text: str
    context: Dict[str, Any] = None
    constraints: List[str] = None
    priority_factors: Dict[str, float] = None
    domain_type: str = "other"
    complexity_level: str = "medium"
    analysis_depth: str = "detailed"
    language_type: str = "chinese"
    privacy_level: str = "normal"
    response_time: str = "normal"

@dataclass
class RequirementAnalysisResult:
    status: str
    parsed_requirements: List[Dict]
    feasibility_report: Dict
    solutions: List[Dict]
    roadmap: Dict
    confidence: float
    processing_time: float
    adapter_used: str
    error_message: str = None

class RequirementAnalysisMCP(BaseWorkflow):
    """éœ€æ±‚åˆ†ææ™ºèƒ½å¼•æ“MCPä¸»ç±»"""
    
    def __init__(self, config_dir: str = None):
        if config_dir is None:
            config_dir = Path(__file__).parent / "config"
        
        super().__init__(str(config_dir))
        self.name = "éœ€æ±‚åˆ†ææ™ºèƒ½å¼•æ“"
        self.version = "1.0.0"
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        self.processors = self._initialize_processors()
        
        # åŠ è½½æµ‹è¯•ç”¨ä¾‹
        self.test_cases = self._load_test_cases()
        
    def _initialize_adapters(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ‰€éœ€çš„adapter"""
        adapters = {}
        
        # è¿™é‡Œåº”è¯¥åˆå§‹åŒ–å®é™…çš„adapter
        # ç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿadapter
        adapters["local_model_mcp"] = MockLocalModelAdapter()
        adapters["cloud_search_mcp"] = MockCloudSearchAdapter()
        
        return adapters
    
    def _initialize_processors(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        return {
            "InputValidator": InputValidator(),
            "RequirementPreprocessor": RequirementPreprocessor(),
            "DomainClassifier": DomainClassifier(),
            "ComplexityAssessor": ComplexityAssessor(),
            "AdapterSelector": AdapterSelector(self.routing_rules),
            "RequirementParser": RequirementParser(),
            "FeasibilityAnalyzer": FeasibilityAnalyzer(),
            "SolutionGenerator": SolutionGenerator(),
            "RiskAssessor": RiskAssessor(),
            "CostEstimator": CostEstimator(),
            "PriorityRanker": PriorityRanker(),
            "ResultFormatter": ResultFormatter(),
            "QualityValidator": QualityValidator(self.quality_settings)
        }
    
    def _load_test_cases(self) -> Dict[str, Any]:
        """åŠ è½½æµ‹è¯•ç”¨ä¾‹ï¼ŒåŒ…å«OCRæµ‹è¯•æ´å¯Ÿ"""
        return {
            "traditional_chinese_ocr": {
                "requirement_text": """
                éœ€è¦å¼€å‘ä¸€ä¸ªèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«ç¹ä½“ä¸­æ–‡ä¿é™©è¡¨å•çš„OCRç³»ç»Ÿã€‚
                ç³»ç»Ÿéœ€è¦å¤„ç†å¤æ‚çš„æ‰‹å†™å†…å®¹ï¼ŒåŒ…æ‹¬å§“åã€åœ°å€ç­‰ä¸ªäººä¿¡æ¯ã€‚
                ç‰¹åˆ«è¦æ±‚èƒ½å¤Ÿæ­£ç¡®è¯†åˆ«å°æ¹¾åœ°å€æ ¼å¼ï¼Œå¦‚'604 å˜‰ç¾©ç¸£ç«¹å´é„‰ç£æ©‹æ‘äº”é–“å58-51è™Ÿ'ã€‚
                ç›®å‰æµ‹è¯•å‘ç°Mistralæ¨¡å‹è¯†åˆ«å§“å'å¼µå®¶éŠ“'æ—¶é”™è¯¯è¯†åˆ«ä¸º'æ—å¿—ç²'ï¼Œ
                Claudeæ¨¡å‹è¯†åˆ«åœ°å€æ—¶ä¹Ÿå‡ºç°ä¸¥é‡åå·®ï¼Œéœ€è¦ä¸“é—¨ä¼˜åŒ–ç¹ä½“ä¸­æ–‡è¯†åˆ«èƒ½åŠ›ã€‚
                """,
                "context": {
                    "domain": "document_processing",
                    "target_language": "traditional_chinese",
                    "document_type": "insurance_forms",
                    "accuracy_requirement": "95%+",
                    "processing_speed": "real_time",
                    "test_findings": {
                        "mistral_errors": ["å§“åè¯†åˆ«é”™è¯¯: å¼µå®¶éŠ“ -> æ—å¿—ç²"],
                        "claude_errors": ["åœ°å€è¯†åˆ«é”™è¯¯: å®Œå…¨é”™è¯¯çš„åœ°å€"],
                        "accuracy_issues": "æ‰‹å†™ç¹ä½“ä¸­æ–‡è¯†åˆ«å‡†ç¡®åº¦ä½äº30%"
                    }
                },
                "constraints": [
                    "å¿…é¡»æ”¯æŒç¹ä½“ä¸­æ–‡",
                    "æ‰‹å†™è¯†åˆ«å‡†ç¡®åº¦è¦æ±‚é«˜",
                    "éœ€è¦å¤„ç†å¤æ‚è¡¨æ ¼ç»“æ„",
                    "ä¿æŠ¤éšç§æ•°æ®"
                ],
                "domain_type": "ocr",
                "complexity_level": "complex",
                "language_type": "chinese"
            },
            "ocr_accuracy_challenge": {
                "requirement_text": """
                å½“å‰OCRç³»ç»Ÿåœ¨è¯†åˆ«ç¹ä½“ä¸­æ–‡æ‰‹å†™å†…å®¹æ—¶å‡†ç¡®åº¦ä¸¥é‡ä¸è¶³ã€‚
                å…·ä½“é—®é¢˜åŒ…æ‹¬ï¼š
                1. å§“åè¯†åˆ«ï¼š'å¼µå®¶éŠ“' è¢«Mistralé”™è¯¯è¯†åˆ«ä¸º'æ—å¿—ç²'
                2. åœ°å€è¯†åˆ«ï¼š'604 å˜‰ç¾©ç¸£ç«¹å´é„‰ç£æ©‹æ‘äº”é–“å58-51è™Ÿ' è¢«Claudeå®Œå…¨è¯†åˆ«é”™è¯¯
                3. é‡‘é¢è¯†åˆ«ï¼šä¿é™©è´¹'13726å…ƒ'ç»å¸¸è¢«è¯†åˆ«ä¸ºå…¶ä»–æ•°å­—
                éœ€è¦æå‡æ‰‹å†™ç¹ä½“ä¸­æ–‡çš„è¯†åˆ«å‡†ç¡®åº¦åˆ°90%ä»¥ä¸Šã€‚
                """,
                "context": {
                    "current_accuracy": "30-50%",
                    "target_accuracy": "90%+",
                    "error_types": ["å§“åè¯†åˆ«", "åœ°å€è¯†åˆ«", "æ•°å­—è¯†åˆ«"],
                    "test_data": "å°æ¹¾ä¿é™©è¡¨å•",
                    "failed_models": ["mistral", "claude"],
                    "specific_errors": {
                        "name_error": "å¼µå®¶éŠ“ -> æ—å¿—ç²",
                        "address_error": "604 å˜‰ç¾©ç¸£ç«¹å´é„‰ç£æ©‹æ‘äº”é–“å58-51è™Ÿ -> é”™è¯¯åœ°å€",
                        "amount_error": "13726å…ƒ -> å…¶ä»–æ•°å­—"
                    }
                },
                "constraints": [
                    "ä¸èƒ½é™ä½å¤„ç†é€Ÿåº¦",
                    "éœ€è¦ä¿æŒæˆæœ¬å¯æ§",
                    "å¿…é¡»æ”¯æŒå®æ—¶å¤„ç†"
                ],
                "domain_type": "ocr",
                "complexity_level": "complex",
                "language_type": "chinese"
            }
        }
    
    async def analyze_requirements(self, request: RequirementAnalysisRequest) -> RequirementAnalysisResult:
        """åˆ†æéœ€æ±‚çš„ä¸»è¦æ–¹æ³•"""
        start_time = time.time()
        
        try:
            # è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼
            context = {
                "request": asdict(request),
                "results": {},
                "metadata": {
                    "start_time": start_time,
                    "workflow_version": self.version
                }
            }
            
            # æ‰§è¡Œå·¥ä½œæµ
            result = await self.execute_workflow(context)
            
            processing_time = time.time() - start_time
            
            return RequirementAnalysisResult(
                status="success",
                parsed_requirements=result.get("parsed_requirements", []),
                feasibility_report=result.get("feasibility_report", {}),
                solutions=result.get("solutions", []),
                roadmap=result.get("roadmap", {}),
                confidence=result.get("confidence", 0.0),
                processing_time=processing_time,
                adapter_used=result.get("adapter_used", "unknown")
            )
            
        except Exception as e:
            self.logger.error(f"éœ€æ±‚åˆ†æå¤±è´¥: {e}")
            processing_time = time.time() - start_time
            
            return RequirementAnalysisResult(
                status="error",
                parsed_requirements=[],
                feasibility_report={},
                solutions=[],
                roadmap={},
                confidence=0.0,
                processing_time=processing_time,
                adapter_used="none",
                error_message=str(e)
            )
    
    async def execute_workflow(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´å·¥ä½œæµ"""
        request = context["request"]
        
        # æ‰§è¡Œæ‰€æœ‰å¤„ç†æ­¥éª¤
        for step in self.processing_steps['steps']:
            if self._should_execute_step(step, context):
                try:
                    result = await self.execute_step(step, context)
                    context['results'][step['id']] = result
                    
                    # è®°å½•å…³é”®æ­¥éª¤ç»“æœ
                    if step['id'] == 'adapter_selection':
                        context['metadata']['adapter_used'] = result.get('selected_adapter', 'unknown')
                        
                except Exception as e:
                    self.logger.error(f"æ­¥éª¤ {step['id']} æ‰§è¡Œå¤±è´¥: {e}")
                    if step.get('required', True):
                        raise e
                    else:
                        context['results'][step['id']] = {"error": str(e)}
        
        return self._format_final_result(context)
    
    async def execute_step(self, step_config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªå¤„ç†æ­¥éª¤"""
        processor_name = step_config['processor']
        processor = self.processors.get(processor_name)
        
        if not processor:
            raise ValueError(f"å¤„ç†å™¨ {processor_name} æœªæ‰¾åˆ°")
        
        # æ‰§è¡Œå¤„ç†å™¨
        if hasattr(processor, 'process_async'):
            return await processor.process_async(context)
        else:
            return processor.process(context)
    
    def _should_execute_step(self, step: Dict[str, Any], context: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡ŒæŸä¸ªæ­¥éª¤"""
        # æ£€æŸ¥æ¡ä»¶
        conditions = step.get('conditions', {})
        if conditions:
            for condition_key, condition_value in conditions.items():
                if condition_key in self.config['analysis_settings']:
                    config_value = self.config['analysis_settings'][condition_key]
                    if not self._evaluate_condition(config_value, condition_value):
                        return False
        
        return True
    
    def _evaluate_condition(self, config_value: Any, condition_value: str) -> bool:
        """è¯„ä¼°æ¡ä»¶è¡¨è¾¾å¼"""
        if condition_value.startswith('>'):
            threshold = float(condition_value[1:].strip())
            return float(config_value) > threshold
        elif condition_value.startswith('<'):
            threshold = float(condition_value[1:].strip())
            return float(config_value) < threshold
        else:
            return str(config_value) == condition_value
    
    def _format_final_result(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æœ€ç»ˆç»“æœ"""
        results = context['results']
        
        return {
            "parsed_requirements": results.get('requirement_parsing', {}).get('requirements', []),
            "feasibility_report": results.get('feasibility_analysis', {}),
            "solutions": results.get('solution_generation', {}).get('solutions', []),
            "roadmap": results.get('priority_ranking', {}).get('roadmap', {}),
            "confidence": results.get('quality_validation', {}).get('overall_confidence', 0.0),
            "adapter_used": context['metadata'].get('adapter_used', 'unknown'),
            "processing_metadata": {
                "steps_executed": list(results.keys()),
                "total_steps": len(self.processing_steps['steps']),
                "workflow_version": self.version
            }
        }
    
    def _handle_workflow_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å·¥ä½œæµé”™è¯¯"""
        return {
            "status": "error",
            "error_message": str(error),
            "partial_results": context.get('results', {}),
            "failed_at": context.get('current_step', 'unknown')
        }

# å¤„ç†å™¨å®ç°ç±»
class InputValidator:
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        request = context["request"]
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ["requirement_text"]
        for field in required_fields:
            if not request.get(field):
                raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # éªŒè¯æ–‡æœ¬é•¿åº¦
        text = request["requirement_text"]
        if len(text) < 10:
            raise ValueError("éœ€æ±‚æè¿°è¿‡çŸ­ï¼Œè‡³å°‘éœ€è¦10ä¸ªå­—ç¬¦")
        if len(text) > 10000:
            raise ValueError("éœ€æ±‚æè¿°è¿‡é•¿ï¼Œæœ€å¤š10000ä¸ªå­—ç¬¦")
        
        return {"status": "valid", "validated_fields": required_fields}

class RequirementPreprocessor:
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        request = context["request"]
        text = request["requirement_text"]
        
        # æ¸…ç†æ–‡æœ¬
        cleaned_text = text.strip()
        cleaned_text = " ".join(cleaned_text.split())  # æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦
        
        return {
            "original_text": text,
            "cleaned_text": cleaned_text,
            "text_length": len(cleaned_text)
        }

class DomainClassifier:
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        request = context["request"]
        text = request["requirement_text"].lower()
        
        # ç®€å•çš„å…³é”®è¯åˆ†ç±»
        domain_keywords = {
            "ocr": ["è¯†åˆ«", "ocr", "æ–‡å­—", "å›¾åƒ", "æ‰«æ", "æ‰‹å†™", "ç¹ä½“", "è¡¨å•"],
            "nlp": ["è‡ªç„¶è¯­è¨€", "æ–‡æœ¬åˆ†æ", "è¯­è¨€æ¨¡å‹", "nlp"],
            "web": ["ç½‘ç«™", "å‰ç«¯", "åç«¯", "api", "web"],
            "ai": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "ai", "äººå·¥æ™ºèƒ½"],
            "vision": ["è®¡ç®—æœºè§†è§‰", "å›¾åƒè¯†åˆ«", "è§†è§‰"]
        }
        
        domain_scores = {}
        for domain, keywords in domain_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            domain_scores[domain] = score
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„é¢†åŸŸ
        classified_domain = max(domain_scores, key=domain_scores.get)
        confidence = domain_scores[classified_domain] / len(domain_keywords[classified_domain])
        
        return {
            "classified_domain": classified_domain,
            "confidence": confidence,
            "domain_scores": domain_scores
        }

class ComplexityAssessor:
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        request = context["request"]
        text = request["requirement_text"]
        
        # ç®€å•çš„å¤æ‚åº¦è¯„ä¼°
        complexity_indicators = {
            "simple": ["ç®€å•", "åŸºç¡€", "åŸºæœ¬"],
            "medium": ["ä¸­ç­‰", "ä¸€èˆ¬", "æ ‡å‡†"],
            "complex": ["å¤æ‚", "é«˜çº§", "å›°éš¾", "æŒ‘æˆ˜", "å¤š", "é›†æˆ"]
        }
        
        complexity_score = 0
        for indicator in complexity_indicators["complex"]:
            if indicator in text:
                complexity_score += 1
        
        if complexity_score >= 2:
            level = "complex"
        elif complexity_score >= 1:
            level = "medium"
        else:
            level = "simple"
        
        return {
            "complexity_level": level,
            "complexity_score": complexity_score,
            "confidence": 0.8
        }

class AdapterSelector:
    def __init__(self, routing_rules: Dict[str, Any]):
        self.routing_rules = routing_rules
    
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        request = context["request"]
        results = context["results"]
        
        # è·å–åˆ†ç±»ç»“æœ
        domain = results.get("domain_classification", {}).get("classified_domain", "other")
        complexity = results.get("complexity_assessment", {}).get("complexity_level", "medium")
        
        # æ ¹æ®è·¯ç”±è§„åˆ™é€‰æ‹©é€‚é…å™¨
        domain_adapter = self.routing_rules["routing_rules"]["domain_type"].get(domain, "local_model_mcp")
        complexity_adapter = self.routing_rules["routing_rules"]["complexity_level"].get(complexity, "local_model_mcp")
        
        # ç®€å•çš„é€‰æ‹©é€»è¾‘ï¼šä¼˜å…ˆè€ƒè™‘é¢†åŸŸ
        selected_adapter = domain_adapter
        
        return {
            "selected_adapter": selected_adapter,
            "domain_recommendation": domain_adapter,
            "complexity_recommendation": complexity_adapter,
            "confidence": 0.9
        }

class RequirementParser:
    async def process_async(self, context: Dict[str, Any]) -> Dict[str, Any]:
        request = context["request"]
        adapter_result = context["results"]["adapter_selection"]
        
        # æ¨¡æ‹ŸAIè§£æ
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        requirements = [
            {
                "id": "req_1",
                "text": "ç¹ä½“ä¸­æ–‡OCRè¯†åˆ«",
                "type": "functional",
                "priority": 1,
                "complexity": 0.9,
                "domain": "ocr",
                "confidence": 0.85
            },
            {
                "id": "req_2", 
                "text": "æ‰‹å†™æ–‡å­—è¯†åˆ«",
                "type": "functional",
                "priority": 2,
                "complexity": 0.95,
                "domain": "ocr",
                "confidence": 0.8
            }
        ]
        
        return {
            "requirements": requirements,
            "parsing_confidence": 0.85,
            "adapter_used": adapter_result["selected_adapter"]
        }

class FeasibilityAnalyzer:
    async def process_async(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # æ¨¡æ‹Ÿå¯è¡Œæ€§åˆ†æ
        await asyncio.sleep(0.1)
        
        return {
            "overall_feasibility": 0.8,
            "technical_challenges": [
                "ç¹ä½“ä¸­æ–‡å­—ç¬¦å¤æ‚åº¦é«˜",
                "æ‰‹å†™æ–‡å­—å˜å½¢ä¸¥é‡",
                "éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®"
            ],
            "resource_requirements": {
                "development_time": "3-6ä¸ªæœˆ",
                "team_size": "3-5äºº",
                "budget_estimate": "50-100ä¸‡"
            },
            "confidence": 0.8
        }

class SolutionGenerator:
    async def process_async(self, context: Dict[str, Any]) -> Dict[str, Any]:
        # æ¨¡æ‹Ÿæ–¹æ¡ˆç”Ÿæˆ
        await asyncio.sleep(0.1)
        
        solutions = [
            {
                "id": "sol_1",
                "title": "å¤šæ¨¡å‹èåˆOCRæ–¹æ¡ˆ",
                "description": "ç»“åˆMistralã€Claudeã€Geminiç­‰å¤šä¸ªæ¨¡å‹ï¼Œé€šè¿‡æŠ•ç¥¨æœºåˆ¶æå‡å‡†ç¡®åº¦",
                "technology_stack": ["Mistral", "Claude", "Gemini", "Python", "FastAPI"],
                "estimated_effort": 90,
                "confidence": 0.9,
                "pros": ["å‡†ç¡®åº¦é«˜", "é²æ£’æ€§å¼º"],
                "cons": ["æˆæœ¬è¾ƒé«˜", "å“åº”æ—¶é—´é•¿"],
                "risks": ["APIä¾èµ–", "æˆæœ¬æ§åˆ¶"],
                "implementation_steps": [
                    "é›†æˆå¤šä¸ªOCRæ¨¡å‹API",
                    "å®ç°æŠ•ç¥¨ç®—æ³•",
                    "ä¼˜åŒ–å“åº”æ—¶é—´",
                    "å»ºç«‹è´¨é‡ç›‘æ§"
                ],
                "timeline_estimate": "3-4ä¸ªæœˆ",
                "cost_estimate": 80000
            },
            {
                "id": "sol_2",
                "title": "ä¸“ç”¨ç¹ä½“ä¸­æ–‡OCRè®­ç»ƒ",
                "description": "åŸºäºå¤§é‡ç¹ä½“ä¸­æ–‡æ•°æ®è®­ç»ƒä¸“ç”¨OCRæ¨¡å‹",
                "technology_stack": ["PyTorch", "Transformers", "ONNX", "Docker"],
                "estimated_effort": 120,
                "confidence": 0.85,
                "pros": ["é’ˆå¯¹æ€§å¼º", "å¯æ§æ€§é«˜"],
                "cons": ["å¼€å‘å‘¨æœŸé•¿", "éœ€è¦å¤§é‡æ•°æ®"],
                "risks": ["è®­ç»ƒæ•°æ®è·å–", "æ¨¡å‹æ€§èƒ½ä¸ç¡®å®š"],
                "implementation_steps": [
                    "æ”¶é›†ç¹ä½“ä¸­æ–‡è®­ç»ƒæ•°æ®",
                    "è®¾è®¡æ¨¡å‹æ¶æ„",
                    "è®­ç»ƒå’Œä¼˜åŒ–æ¨¡å‹",
                    "éƒ¨ç½²å’Œæµ‹è¯•"
                ],
                "timeline_estimate": "4-6ä¸ªæœˆ",
                "cost_estimate": 120000
            }
        ]
        
        return {
            "solutions": solutions,
            "generation_confidence": 0.88
        }

class RiskAssessor:
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "risk_factors": [
                "æŠ€æœ¯å¤æ‚åº¦é«˜",
                "æ•°æ®è´¨é‡ä¾èµ–",
                "æˆæœ¬æ§åˆ¶æŒ‘æˆ˜"
            ],
            "risk_levels": {
                "technical": "high",
                "cost": "medium", 
                "timeline": "medium"
            },
            "confidence": 0.8
        }

class CostEstimator:
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "development_cost": 100000,
            "operational_cost": 20000,
            "total_cost": 120000,
            "confidence": 0.75
        }

class PriorityRanker:
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        solutions = context["results"]["solution_generation"]["solutions"]
        
        # ç®€å•çš„ä¼˜å…ˆçº§æ’åº
        ranked_solutions = sorted(solutions, key=lambda x: x["confidence"], reverse=True)
        
        roadmap = {
            "phase_1": "éœ€æ±‚åˆ†æå’ŒæŠ€æœ¯è°ƒç ”",
            "phase_2": "åŸå‹å¼€å‘å’Œæµ‹è¯•",
            "phase_3": "ç³»ç»Ÿé›†æˆå’Œä¼˜åŒ–",
            "phase_4": "éƒ¨ç½²å’Œè¿ç»´"
        }
        
        return {
            "ranked_solutions": ranked_solutions,
            "roadmap": roadmap,
            "ranking_confidence": 0.85
        }

class ResultFormatter:
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "format": "json",
            "timestamp": time.time(),
            "version": "1.0.0"
        }

class QualityValidator:
    def __init__(self, quality_settings: Dict[str, Any]):
        self.quality_settings = quality_settings
    
    def process(self, context: Dict[str, Any]) -> Dict[str, Any]:
        results = context["results"]
        
        # è®¡ç®—æ€»ä½“ç½®ä¿¡åº¦
        confidences = []
        for step_result in results.values():
            if isinstance(step_result, dict) and "confidence" in step_result:
                confidences.append(step_result["confidence"])
        
        overall_confidence = sum(confidences) / len(confidences) if confidences else 0.0
        
        # æ£€æŸ¥è´¨é‡é˜ˆå€¼
        min_threshold = self.quality_settings["quality"]["min_confidence"]
        quality_passed = overall_confidence >= min_threshold
        
        return {
            "overall_confidence": overall_confidence,
            "quality_passed": quality_passed,
            "individual_confidences": confidences,
            "quality_threshold": min_threshold
        }

# æ¨¡æ‹Ÿé€‚é…å™¨ç±»
class MockLocalModelAdapter:
    async def process(self, request: Dict[str, Any]) -> Dict[str, Any]:
        await asyncio.sleep(0.1)
        return {"result": "local_model_result", "confidence": 0.8}

class MockCloudSearchAdapter:
    async def process(self, request: Dict[str, Any]) -> Dict[str, Any]:
        await asyncio.sleep(0.2)
        return {"result": "cloud_search_result", "confidence": 0.9}

# æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œå™¨
class RequirementAnalysisTestRunner:
    """éœ€æ±‚åˆ†ææµ‹è¯•ç”¨ä¾‹æ‰§è¡Œå™¨"""
    
    def __init__(self, mcp: RequirementAnalysisMCP):
        self.mcp = mcp
    
    async def run_ocr_test_cases(self) -> Dict[str, Any]:
        """è¿è¡ŒOCRç›¸å…³çš„æµ‹è¯•ç”¨ä¾‹"""
        results = {}
        
        # æµ‹è¯•ç¹ä½“ä¸­æ–‡OCRéœ€æ±‚åˆ†æ
        traditional_chinese_case = self.mcp.test_cases["traditional_chinese_ocr"]
        traditional_chinese_request = RequirementAnalysisRequest(**traditional_chinese_case)
        
        traditional_chinese_result = await self.mcp.analyze_requirements(traditional_chinese_request)
        results["traditional_chinese_ocr"] = asdict(traditional_chinese_result)
        
        # æµ‹è¯•OCRå‡†ç¡®åº¦æŒ‘æˆ˜åˆ†æ
        accuracy_challenge_case = self.mcp.test_cases["ocr_accuracy_challenge"]
        accuracy_challenge_request = RequirementAnalysisRequest(**accuracy_challenge_case)
        
        accuracy_challenge_result = await self.mcp.analyze_requirements(accuracy_challenge_request)
        results["accuracy_challenge"] = asdict(accuracy_challenge_result)
        
        return results
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹"""
        ocr_results = await self.run_ocr_test_cases()
        
        return {
            "test_summary": {
                "total_tests": len(ocr_results),
                "passed_tests": sum(1 for r in ocr_results.values() if r["status"] == "success"),
                "failed_tests": sum(1 for r in ocr_results.values() if r["status"] == "error")
            },
            "test_results": ocr_results
        }

if __name__ == "__main__":
    # MCPå¯åŠ¨å…¥å£
    async def main():
        # åˆå§‹åŒ–MCP
        config_dir = Path(__file__).parent / "config"
        mcp = RequirementAnalysisMCP(str(config_dir))
        
        print(f"ğŸš€ å¯åŠ¨ {mcp.name} v{mcp.version}")
        
        # è¿è¡Œæµ‹è¯•ç”¨ä¾‹
        test_runner = RequirementAnalysisTestRunner(mcp)
        test_results = await test_runner.run_all_tests()
        
        print("\nğŸ“Š éœ€æ±‚åˆ†ææµ‹è¯•ç»“æœ:")
        print(json.dumps(test_results, indent=2, ensure_ascii=False))
        
        # è¿è¡Œå•ä¸ªæµ‹è¯•ç¤ºä¾‹
        print("\nğŸ§ª è¿è¡Œå•ä¸ªæµ‹è¯•ç¤ºä¾‹:")
        sample_request = RequirementAnalysisRequest(
            requirement_text="éœ€è¦å¼€å‘ä¸€ä¸ªç¹ä½“ä¸­æ–‡OCRç³»ç»Ÿï¼Œèƒ½å¤Ÿè¯†åˆ«æ‰‹å†™æ–‡å­—",
            domain_type="ocr",
            complexity_level="complex",
            language_type="chinese"
        )
        
        result = await mcp.analyze_requirements(sample_request)
        print(json.dumps(asdict(result), indent=2, ensure_ascii=False))
    
    asyncio.run(main())

